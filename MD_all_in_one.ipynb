{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/Mohammed/Desktop/SMALLMOL_MD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += \":/opt/homebrew/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P1\n",
      "⚠️  SMALLMOL 1 directory not found, skipping...\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P2\n",
      "✅  md_whole.xtc already exists for P2 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P2 rep1\n",
      "✅  md_whole.xtc already exists for P2 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P2 rep2\n",
      "✅  md_whole.xtc already exists for P2 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P2 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P3\n",
      "✅  md_whole.xtc already exists for P3 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P3 rep1\n",
      "✅  md_whole.xtc already exists for P3 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P3 rep2\n",
      "✅  md_whole.xtc already exists for P3 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P3 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P4\n",
      "✅  md_whole.xtc already exists for P4 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P4 rep1\n",
      "✅  md_whole.xtc already exists for P4 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P4 rep2\n",
      "✅  md_whole.xtc already exists for P4 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P4 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P5\n",
      "✅  md_whole.xtc already exists for P5 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P5 rep1\n",
      "✅  md_whole.xtc already exists for P5 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P5 rep2\n",
      "✅  md_whole.xtc already exists for P5 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P5 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P6\n",
      "✅  md_whole.xtc already exists for P6 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P6 rep1\n",
      "✅  md_whole.xtc already exists for P6 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P6 rep2\n",
      "✅  md_whole.xtc already exists for P6 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P6 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P7\n",
      "✅  md_whole.xtc already exists for P7 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P7 rep1\n",
      "✅  md_whole.xtc already exists for P7 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P7 rep2\n",
      "✅  md_whole.xtc already exists for P7 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P7 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P8\n",
      "✅  md_whole.xtc already exists for P8 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P8 rep1\n",
      "✅  md_whole.xtc already exists for P8 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P8 rep2\n",
      "✅  md_whole.xtc already exists for P8 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P8 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P9\n",
      "✅  md_whole.xtc already exists for P9 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P9 rep1\n",
      "✅  md_whole.xtc already exists for P9 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P9 rep2\n",
      "✅  md_whole.xtc already exists for P9 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P9 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P10\n",
      "✅  md_whole.xtc already exists for P10 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P10 rep1\n",
      "✅  md_whole.xtc already exists for P10 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P10 rep2\n",
      "✅  md_whole.xtc already exists for P10 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P10 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P11\n",
      "✅  md_whole.xtc already exists for P11 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P11 rep1\n",
      "✅  md_whole.xtc already exists for P11 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P11 rep2\n",
      "✅  md_whole.xtc already exists for P11 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P11 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P12\n",
      "✅  md_whole.xtc already exists for P12 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P12 rep1\n",
      "✅  md_whole.xtc already exists for P12 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P12 rep2\n",
      "✅  md_whole.xtc already exists for P12 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P12 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P13\n",
      "✅  md_whole.xtc already exists for P13 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P13 rep1\n",
      "✅  md_whole.xtc already exists for P13 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P13 rep2\n",
      "✅  md_whole.xtc already exists for P13 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P13 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P14\n",
      "✅  md_whole.xtc already exists for P14 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P14 rep1\n",
      "✅  md_whole.xtc already exists for P14 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P14 rep2\n",
      "✅  md_whole.xtc already exists for P14 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P14 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P15\n",
      "✅  md_whole.xtc already exists for P15 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P15 rep1\n",
      "✅  md_whole.xtc already exists for P15 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P15 rep2\n",
      "✅  md_whole.xtc already exists for P15 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P15 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P16\n",
      "✅  md_whole.xtc already exists for P16 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P16 rep1\n",
      "✅  md_whole.xtc already exists for P16 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P16 rep2\n",
      "✅  md_whole.xtc already exists for P16 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P16 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P17\n",
      "✅  md_whole.xtc already exists for P17 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P17 rep1\n",
      "✅  md_whole.xtc already exists for P17 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P17 rep2\n",
      "✅  md_whole.xtc already exists for P17 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P17 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P18\n",
      "✅  md_whole.xtc already exists for P18 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P18 rep1\n",
      "✅  md_whole.xtc already exists for P18 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P18 rep2\n",
      "✅  md_whole.xtc already exists for P18 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P18 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P19\n",
      "✅  md_whole.xtc already exists for P19 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P19 rep1\n",
      "✅  md_whole.xtc already exists for P19 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P19 rep2\n",
      "✅  md_whole.xtc already exists for P19 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P19 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P20\n",
      "✅  md_whole.xtc already exists for P20 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P20 rep1\n",
      "✅  md_whole.xtc already exists for P20 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P20 rep2\n",
      "✅  md_whole.xtc already exists for P20 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P20 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P21\n",
      "✅  md_whole.xtc already exists for P21 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P21 rep1\n",
      "✅  md_whole.xtc already exists for P21 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P21 rep2\n",
      "✅  md_whole.xtc already exists for P21 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P21 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P22\n",
      "✅  md_whole.xtc already exists for P22 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P22 rep1\n",
      "✅  md_whole.xtc already exists for P22 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P22 rep2\n",
      "✅  md_whole.xtc already exists for P22 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P22 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P23\n",
      "✅  md_whole.xtc already exists for P23 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P23 rep1\n",
      "✅  md_whole.xtc already exists for P23 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P23 rep2\n",
      "✅  md_whole.xtc already exists for P23 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P23 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P24\n",
      "✅  md_whole.xtc already exists for P24 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P24 rep1\n",
      "✅  md_whole.xtc already exists for P24 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P24 rep2\n",
      "✅  md_whole.xtc already exists for P24 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P24 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P25\n",
      "⚠️  SMALLMOL 25 directory not found, skipping...\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P26\n",
      "✅  md_whole.xtc already exists for P26 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P26 rep1\n",
      "✅  md_whole.xtc already exists for P26 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P26 rep2\n",
      "✅  md_whole.xtc already exists for P26 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P26 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P27\n",
      "✅  md_whole.xtc already exists for P27 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P27 rep1\n",
      "✅  md_whole.xtc already exists for P27 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P27 rep2\n",
      "✅  md_whole.xtc already exists for P27 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P27 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P28\n",
      "✅  md_whole.xtc already exists for P28 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P28 rep1\n",
      "✅  md_whole.xtc already exists for P28 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P28 rep2\n",
      "✅  md_whole.xtc already exists for P28 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P28 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P29\n",
      "✅  md_whole.xtc already exists for P29 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P29 rep1\n",
      "✅  md_whole.xtc already exists for P29 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P29 rep2\n",
      "✅  md_whole.xtc already exists for P29 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P29 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P30\n",
      "⚠️  SMALLMOL 30 directory not found, skipping...\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P31\n",
      "✅  md_whole.xtc already exists for P31 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P31 rep1\n",
      "✅  md_whole.xtc already exists for P31 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P31 rep2\n",
      "✅  md_whole.xtc already exists for P31 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P31 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P32\n",
      "✅  md_whole.xtc already exists for P32 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P32 rep1\n",
      "✅  md_whole.xtc already exists for P32 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P32 rep2\n",
      "✅  md_whole.xtc already exists for P32 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P32 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P33\n",
      "✅  md_whole.xtc already exists for P33 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P33 rep1\n",
      "✅  md_whole.xtc already exists for P33 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P33 rep2\n",
      "✅  md_whole.xtc already exists for P33 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P33 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P34\n",
      "✅  md_whole.xtc already exists for P34 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P34 rep1\n",
      "✅  md_whole.xtc already exists for P34 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P34 rep2\n",
      "✅  md_whole.xtc already exists for P34 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P34 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P35\n",
      "✅  md_whole.xtc already exists for P35 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P35 rep1\n",
      "✅  md_whole.xtc already exists for P35 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P35 rep2\n",
      "✅  md_whole.xtc already exists for P35 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P35 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P36\n",
      "✅  md_whole.xtc already exists for P36 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P36 rep1\n",
      "✅  md_whole.xtc already exists for P36 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P36 rep2\n",
      "✅  md_whole.xtc already exists for P36 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P36 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P37\n",
      "✅  md_whole.xtc already exists for P37 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P37 rep1\n",
      "✅  md_whole.xtc already exists for P37 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P37 rep2\n",
      "✅  md_whole.xtc already exists for P37 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P37 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P38\n",
      "✅  md_whole.xtc already exists for P38 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P38 rep1\n",
      "✅  md_whole.xtc already exists for P38 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P38 rep2\n",
      "✅  md_whole.xtc already exists for P38 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P38 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P39\n",
      "✅  md_whole.xtc already exists for P39 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P39 rep1\n",
      "✅  md_whole.xtc already exists for P39 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P39 rep2\n",
      "✅  md_whole.xtc already exists for P39 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P39 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P40\n",
      "✅  md_whole.xtc already exists for P40 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P40 rep1\n",
      "✅  md_whole.xtc already exists for P40 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P40 rep2\n",
      "✅  md_whole.xtc already exists for P40 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P40 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P41\n",
      "✅  md_whole.xtc already exists for P41 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P41 rep1\n",
      "✅  md_whole.xtc already exists for P41 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P41 rep2\n",
      "✅  md_whole.xtc already exists for P41 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P41 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P42\n",
      "✅  md_whole.xtc already exists for P42 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P42 rep1\n",
      "✅  md_whole.xtc already exists for P42 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P42 rep2\n",
      "✅  md_whole.xtc already exists for P42 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P42 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P43\n",
      "⚠️  SMALLMOL 43 directory not found, skipping...\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P44\n",
      "✅  md_whole.xtc already exists for P44 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P44 rep1\n",
      "✅  md_whole.xtc already exists for P44 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P44 rep2\n",
      "✅  md_whole.xtc already exists for P44 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P44 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P45\n",
      "✅  md_whole.xtc already exists for P45 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P45 rep1\n",
      "✅  md_whole.xtc already exists for P45 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P45 rep2\n",
      "✅  md_whole.xtc already exists for P45 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P45 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P46\n",
      "⚠️  SMALLMOL 46 directory not found, skipping...\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P47\n",
      "✅  md_whole.xtc already exists for P47 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P47 rep1\n",
      "✅  md_whole.xtc already exists for P47 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P47 rep2\n",
      "✅  md_whole.xtc already exists for P47 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P47 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P48\n",
      "✅  md_whole.xtc already exists for P48 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P48 rep1\n",
      "✅  md_whole.xtc already exists for P48 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P48 rep2\n",
      "✅  md_whole.xtc already exists for P48 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P48 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P49\n",
      "⚠️  SMALLMOL 49 directory not found, skipping...\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P50\n",
      "✅  md_whole.xtc already exists for P50 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P50 rep1\n",
      "✅  md_whole.xtc already exists for P50 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P50 rep2\n",
      "✅  md_whole.xtc already exists for P50 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P50 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P51\n",
      "✅  md_whole.xtc already exists for P51 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P51 rep1\n",
      "✅  md_whole.xtc already exists for P51 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P51 rep2\n",
      "✅  md_whole.xtc already exists for P51 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P51 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P52\n",
      "✅  md_whole.xtc already exists for P52 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P52 rep1\n",
      "✅  md_whole.xtc already exists for P52 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P52 rep2\n",
      "✅  md_whole.xtc already exists for P52 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P52 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P53\n",
      "✅  md_whole.xtc already exists for P53 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P53 rep1\n",
      "✅  md_whole.xtc already exists for P53 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P53 rep2\n",
      "✅  md_whole.xtc already exists for P53 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P53 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P54\n",
      "✅  md_whole.xtc already exists for P54 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P54 rep1\n",
      "✅  md_whole.xtc already exists for P54 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P54 rep2\n",
      "✅  md_whole.xtc already exists for P54 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P54 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P55\n",
      "✅  md_whole.xtc already exists for P55 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P55 rep1\n",
      "✅  md_whole.xtc already exists for P55 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P55 rep2\n",
      "✅  md_whole.xtc already exists for P55 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P55 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P56\n",
      "✅  md_whole.xtc already exists for P56 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P56 rep1\n",
      "✅  md_whole.xtc already exists for P56 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P56 rep2\n",
      "✅  md_whole.xtc already exists for P56 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P56 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P57\n",
      "✅  md_whole.xtc already exists for P57 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P57 rep1\n",
      "✅  md_whole.xtc already exists for P57 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P57 rep2\n",
      "✅  md_whole.xtc already exists for P57 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P57 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P58\n",
      "✅  md_whole.xtc already exists for P58 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P58 rep1\n",
      "✅  md_whole.xtc already exists for P58 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P58 rep2\n",
      "✅  md_whole.xtc already exists for P58 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P58 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P59\n",
      "✅  md_whole.xtc already exists for P59 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P59 rep1\n",
      "✅  md_whole.xtc already exists for P59 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P59 rep2\n",
      "✅  md_whole.xtc already exists for P59 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P59 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P60\n",
      "✅  md_whole.xtc already exists for P60 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P60 rep1\n",
      "✅  md_whole.xtc already exists for P60 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P60 rep2\n",
      "✅  md_whole.xtc already exists for P60 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P60 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P61\n",
      "✅  md_whole.xtc already exists for P61 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P61 rep1\n",
      "✅  md_whole.xtc already exists for P61 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P61 rep2\n",
      "✅  md_whole.xtc already exists for P61 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P61 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P62\n",
      "✅  md_whole.xtc already exists for P62 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P62 rep1\n",
      "✅  md_whole.xtc already exists for P62 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P62 rep2\n",
      "✅  md_whole.xtc already exists for P62 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P62 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P63\n",
      "✅  md_whole.xtc already exists for P63 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P63 rep1\n",
      "✅  md_whole.xtc already exists for P63 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P63 rep2\n",
      "✅  md_whole.xtc already exists for P63 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P63 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P64\n",
      "✅  md_whole.xtc already exists for P64 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P64 rep1\n",
      "✅  md_whole.xtc already exists for P64 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P64 rep2\n",
      "✅  md_whole.xtc already exists for P64 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P64 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P65\n",
      "✅  md_whole.xtc already exists for P65 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P65 rep1\n",
      "✅  md_whole.xtc already exists for P65 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P65 rep2\n",
      "✅  md_whole.xtc already exists for P65 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P65 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P66\n",
      "✅  md_whole.xtc already exists for P66 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P66 rep1\n",
      "✅  md_whole.xtc already exists for P66 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P66 rep2\n",
      "✅  md_whole.xtc already exists for P66 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P66 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P67\n",
      "✅  md_whole.xtc already exists for P67 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P67 rep1\n",
      "✅  md_whole.xtc already exists for P67 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P67 rep2\n",
      "✅  md_whole.xtc already exists for P67 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P67 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P68\n",
      "✅  md_whole.xtc already exists for P68 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P68 rep1\n",
      "✅  md_whole.xtc already exists for P68 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P68 rep2\n",
      "✅  md_whole.xtc already exists for P68 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P68 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P69\n",
      "✅  md_whole.xtc already exists for P69 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P69 rep1\n",
      "✅  md_whole.xtc already exists for P69 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P69 rep2\n",
      "✅  md_whole.xtc already exists for P69 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P69 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P70\n",
      "✅  md_whole.xtc already exists for P70 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P70 rep1\n",
      "✅  md_whole.xtc already exists for P70 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P70 rep2\n",
      "✅  md_whole.xtc already exists for P70 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P70 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P71\n",
      "✅  md_whole.xtc already exists for P71 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P71 rep1\n",
      "✅  md_whole.xtc already exists for P71 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P71 rep2\n",
      "✅  md_whole.xtc already exists for P71 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P71 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P72\n",
      "✅  md_whole.xtc already exists for P72 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P72 rep1\n",
      "✅  md_whole.xtc already exists for P72 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P72 rep2\n",
      "✅  md_whole.xtc already exists for P72 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P72 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P73\n",
      "✅  md_whole.xtc already exists for P73 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P73 rep1\n",
      "✅  md_whole.xtc already exists for P73 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P73 rep2\n",
      "✅  md_whole.xtc already exists for P73 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P73 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P74\n",
      "✅  md_whole.xtc already exists for P74 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P74 rep1\n",
      "✅  md_whole.xtc already exists for P74 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P74 rep2\n",
      "✅  md_whole.xtc already exists for P74 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P74 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P75\n",
      "✅  md_whole.xtc already exists for P75 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P75 rep1\n",
      "✅  md_whole.xtc already exists for P75 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P75 rep2\n",
      "✅  md_whole.xtc already exists for P75 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P75 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P76\n",
      "✅  md_whole.xtc already exists for P76 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P76 rep1\n",
      "✅  md_whole.xtc already exists for P76 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P76 rep2\n",
      "✅  md_whole.xtc already exists for P76 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P76 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P77\n",
      "✅  md_whole.xtc already exists for P77 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P77 rep1\n",
      "✅  md_whole.xtc already exists for P77 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P77 rep2\n",
      "✅  md_whole.xtc already exists for P77 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P77 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P78\n",
      "✅  md_whole.xtc already exists for P78 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P78 rep1\n",
      "✅  md_whole.xtc already exists for P78 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P78 rep2\n",
      "✅  md_whole.xtc already exists for P78 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P78 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P79\n",
      "✅  md_whole.xtc already exists for P79 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P79 rep1\n",
      "✅  md_whole.xtc already exists for P79 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P79 rep2\n",
      "✅  md_whole.xtc already exists for P79 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P79 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P80\n",
      "✅  md_whole.xtc already exists for P80 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P80 rep1\n",
      "✅  md_whole.xtc already exists for P80 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P80 rep2\n",
      "✅  md_whole.xtc already exists for P80 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P80 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P81\n",
      "✅  md_whole.xtc already exists for P81 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P81 rep1\n",
      "✅  md_whole.xtc already exists for P81 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P81 rep2\n",
      "✅  md_whole.xtc already exists for P81 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P81 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P82\n",
      "✅  md_whole.xtc already exists for P82 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P82 rep1\n",
      "✅  md_whole.xtc already exists for P82 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P82 rep2\n",
      "✅  md_whole.xtc already exists for P82 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P82 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P83\n",
      "✅  md_whole.xtc already exists for P83 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P83 rep1\n",
      "✅  md_whole.xtc already exists for P83 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P83 rep2\n",
      "✅  md_whole.xtc already exists for P83 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P83 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P84\n",
      "✅  md_whole.xtc already exists for P84 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P84 rep1\n",
      "✅  md_whole.xtc already exists for P84 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P84 rep2\n",
      "✅  md_whole.xtc already exists for P84 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P84 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P85\n",
      "✅  md_whole.xtc already exists for P85 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P85 rep1\n",
      "✅  md_whole.xtc already exists for P85 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P85 rep2\n",
      "✅  md_whole.xtc already exists for P85 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P85 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P86\n",
      "✅  md_whole.xtc already exists for P86 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P86 rep1\n",
      "✅  md_whole.xtc already exists for P86 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P86 rep2\n",
      "✅  md_whole.xtc already exists for P86 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P86 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P87\n",
      "✅  md_whole.xtc already exists for P87 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P87 rep1\n",
      "✅  md_whole.xtc already exists for P87 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P87 rep2\n",
      "✅  md_whole.xtc already exists for P87 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P87 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P88\n",
      "✅  md_whole.xtc already exists for P88 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P88 rep1\n",
      "✅  md_whole.xtc already exists for P88 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P88 rep2\n",
      "✅  md_whole.xtc already exists for P88 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P88 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P89\n",
      "✅  md_whole.xtc already exists for P89 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P89 rep1\n",
      "✅  md_whole.xtc already exists for P89 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P89 rep2\n",
      "✅  md_whole.xtc already exists for P89 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P89 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P90\n",
      "✅  md_whole.xtc already exists for P90 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P90 rep1\n",
      "✅  md_whole.xtc already exists for P90 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P90 rep2\n",
      "✅  md_whole.xtc already exists for P90 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P90 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P91\n",
      "✅  md_whole.xtc already exists for P91 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P91 rep1\n",
      "✅  md_whole.xtc already exists for P91 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P91 rep2\n",
      "✅  md_whole.xtc already exists for P91 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P91 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P92\n",
      "✅  md_whole.xtc already exists for P92 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P92 rep1\n",
      "✅  md_whole.xtc already exists for P92 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P92 rep2\n",
      "✅  md_whole.xtc already exists for P92 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P92 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P93\n",
      "✅  md_whole.xtc already exists for P93 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P93 rep1\n",
      "✅  md_whole.xtc already exists for P93 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P93 rep2\n",
      "✅  md_whole.xtc already exists for P93 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P93 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P94\n",
      "✅  md_whole.xtc already exists for P94 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P94 rep1\n",
      "✅  md_whole.xtc already exists for P94 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P94 rep2\n",
      "✅  md_whole.xtc already exists for P94 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P94 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P95\n",
      "✅  md_whole.xtc already exists for P95 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P95 rep1\n",
      "✅  md_whole.xtc already exists for P95 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P95 rep2\n",
      "✅  md_whole.xtc already exists for P95 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P95 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P96\n",
      "✅  md_whole.xtc already exists for P96 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P96 rep1\n",
      "✅  md_whole.xtc already exists for P96 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P96 rep2\n",
      "✅  md_whole.xtc already exists for P96 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P96 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P97\n",
      "✅  md_whole.xtc already exists for P97 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P97 rep1\n",
      "✅  md_whole.xtc already exists for P97 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P97 rep2\n",
      "✅  md_whole.xtc already exists for P97 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P97 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P98\n",
      "✅  md_whole.xtc already exists for P98 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P98 rep1\n",
      "✅  md_whole.xtc already exists for P98 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P98 rep2\n",
      "✅  md_whole.xtc already exists for P98 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P98 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P99\n",
      "✅  md_whole.xtc already exists for P99 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P99 rep1\n",
      "✅  md_whole.xtc already exists for P99 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P99 rep2\n",
      "✅  md_whole.xtc already exists for P99 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P99 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P100\n",
      "✅  md_whole.xtc already exists for P100 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P100 rep1\n",
      "✅  md_whole.xtc already exists for P100 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P100 rep2\n",
      "✅  md_whole.xtc already exists for P100 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P100 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P101\n",
      "✅  md_whole.xtc already exists for P101 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P101 rep1\n",
      "✅  md_whole.xtc already exists for P101 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P101 rep2\n",
      "✅  md_whole.xtc already exists for P101 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P101 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P102\n",
      "✅  md_whole.xtc already exists for P102 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P102 rep1\n",
      "✅  md_whole.xtc already exists for P102 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P102 rep2\n",
      "✅  md_whole.xtc already exists for P102 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P102 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P103\n",
      "✅  md_whole.xtc already exists for P103 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P103 rep1\n",
      "✅  md_whole.xtc already exists for P103 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P103 rep2\n",
      "✅  md_whole.xtc already exists for P103 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P103 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P104\n",
      "✅  md_whole.xtc already exists for P104 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P104 rep1\n",
      "✅  md_whole.xtc already exists for P104 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P104 rep2\n",
      "✅  md_whole.xtc already exists for P104 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P104 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P105\n",
      "✅  md_whole.xtc already exists for P105 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P105 rep1\n",
      "✅  md_whole.xtc already exists for P105 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P105 rep2\n",
      "✅  md_whole.xtc already exists for P105 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P105 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P106\n",
      "✅  md_whole.xtc already exists for P106 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P106 rep1\n",
      "✅  md_whole.xtc already exists for P106 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P106 rep2\n",
      "✅  md_whole.xtc already exists for P106 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P106 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P107\n",
      "✅  md_whole.xtc already exists for P107 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P107 rep1\n",
      "✅  md_whole.xtc already exists for P107 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P107 rep2\n",
      "✅  md_whole.xtc already exists for P107 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P107 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P108\n",
      "✅  md_whole.xtc already exists for P108 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P108 rep1\n",
      "✅  md_whole.xtc already exists for P108 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P108 rep2\n",
      "✅  md_whole.xtc already exists for P108 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P108 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P109\n",
      "✅  md_whole.xtc already exists for P109 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P109 rep1\n",
      "✅  md_whole.xtc already exists for P109 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P109 rep2\n",
      "✅  md_whole.xtc already exists for P109 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P109 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P110\n",
      "✅  md_whole.xtc already exists for P110 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P110 rep1\n",
      "✅  md_whole.xtc already exists for P110 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P110 rep2\n",
      "✅  md_whole.xtc already exists for P110 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P110 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P111\n",
      "✅  md_whole.xtc already exists for P111 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P111 rep1\n",
      "✅  md_whole.xtc already exists for P111 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P111 rep2\n",
      "✅  md_whole.xtc already exists for P111 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P111 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P112\n",
      "✅  md_whole.xtc already exists for P112 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P112 rep1\n",
      "✅  md_whole.xtc already exists for P112 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P112 rep2\n",
      "✅  md_whole.xtc already exists for P112 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P112 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P113\n",
      "✅  md_whole.xtc already exists for P113 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P113 rep1\n",
      "✅  md_whole.xtc already exists for P113 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P113 rep2\n",
      "✅  md_whole.xtc already exists for P113 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P113 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P114\n",
      "✅  md_whole.xtc already exists for P114 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P114 rep1\n",
      "✅  md_whole.xtc already exists for P114 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P114 rep2\n",
      "✅  md_whole.xtc already exists for P114 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P114 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P115\n",
      "✅  md_whole.xtc already exists for P115 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P115 rep1\n",
      "✅  md_whole.xtc already exists for P115 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P115 rep2\n",
      "✅  md_whole.xtc already exists for P115 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P115 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P116\n",
      "✅  md_whole.xtc already exists for P116 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P116 rep1\n",
      "✅  md_whole.xtc already exists for P116 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P116 rep2\n",
      "✅  md_whole.xtc already exists for P116 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P116 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P117\n",
      "✅  md_whole.xtc already exists for P117 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P117 rep1\n",
      "✅  md_whole.xtc already exists for P117 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P117 rep2\n",
      "✅  md_whole.xtc already exists for P117 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P117 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P118\n",
      "✅  md_whole.xtc already exists for P118 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P118 rep1\n",
      "✅  md_whole.xtc already exists for P118 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P118 rep2\n",
      "✅  md_whole.xtc already exists for P118 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P118 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P119\n",
      "✅  md_whole.xtc already exists for P119 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P119 rep1\n",
      "✅  md_whole.xtc already exists for P119 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P119 rep2\n",
      "✅  md_whole.xtc already exists for P119 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P119 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P120\n",
      "✅  md_whole.xtc already exists for P120 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P120 rep1\n",
      "✅  md_whole.xtc already exists for P120 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P120 rep2\n",
      "✅  md_whole.xtc already exists for P120 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P120 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P121\n",
      "✅  md_whole.xtc already exists for P121 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P121 rep1\n",
      "✅  md_whole.xtc already exists for P121 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P121 rep2\n",
      "✅  md_whole.xtc already exists for P121 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P121 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P122\n",
      "✅  md_whole.xtc already exists for P122 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P122 rep1\n",
      "✅  md_whole.xtc already exists for P122 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P122 rep2\n",
      "✅  md_whole.xtc already exists for P122 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P122 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P123\n",
      "✅  md_whole.xtc already exists for P123 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P123 rep1\n",
      "✅  md_whole.xtc already exists for P123 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P123 rep2\n",
      "✅  md_whole.xtc already exists for P123 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P123 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P124\n",
      "✅  md_whole.xtc already exists for P124 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P124 rep1\n",
      "✅  md_whole.xtc already exists for P124 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P124 rep2\n",
      "✅  md_whole.xtc already exists for P124 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P124 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P125\n",
      "✅  md_whole.xtc already exists for P125 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P125 rep1\n",
      "✅  md_whole.xtc already exists for P125 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P125 rep2\n",
      "✅  md_whole.xtc already exists for P125 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P125 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P126\n",
      "✅  md_whole.xtc already exists for P126 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P126 rep1\n",
      "✅  md_whole.xtc already exists for P126 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P126 rep2\n",
      "✅  md_whole.xtc already exists for P126 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P126 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P127\n",
      "✅  md_whole.xtc already exists for P127 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P127 rep1\n",
      "✅  md_whole.xtc already exists for P127 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P127 rep2\n",
      "✅  md_whole.xtc already exists for P127 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P127 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P128\n",
      "✅  md_whole.xtc already exists for P128 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P128 rep1\n",
      "✅  md_whole.xtc already exists for P128 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P128 rep2\n",
      "✅  md_whole.xtc already exists for P128 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P128 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P129\n",
      "✅  md_whole.xtc already exists for P129 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P129 rep1\n",
      "✅  md_whole.xtc already exists for P129 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P129 rep2\n",
      "✅  md_whole.xtc already exists for P129 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P129 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P130\n",
      "✅  md_whole.xtc already exists for P130 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P130 rep1\n",
      "✅  md_whole.xtc already exists for P130 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P130 rep2\n",
      "✅  md_whole.xtc already exists for P130 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P130 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P131\n",
      "✅  md_whole.xtc already exists for P131 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P131 rep1\n",
      "✅  md_whole.xtc already exists for P131 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P131 rep2\n",
      "✅  md_whole.xtc already exists for P131 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P131 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P132\n",
      "✅  md_whole.xtc already exists for P132 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P132 rep1\n",
      "✅  md_whole.xtc already exists for P132 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P132 rep2\n",
      "✅  md_whole.xtc already exists for P132 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P132 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P133\n",
      "✅  md_whole.xtc already exists for P133 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P133 rep1\n",
      "✅  md_whole.xtc already exists for P133 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P133 rep2\n",
      "✅  md_whole.xtc already exists for P133 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P133 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P134\n",
      "✅  md_whole.xtc already exists for P134 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P134 rep1\n",
      "✅  md_whole.xtc already exists for P134 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P134 rep2\n",
      "✅  md_whole.xtc already exists for P134 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P134 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P135\n",
      "✅  md_whole.xtc already exists for P135 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P135 rep1\n",
      "✅  md_whole.xtc already exists for P135 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P135 rep2\n",
      "✅  md_whole.xtc already exists for P135 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P135 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P136\n",
      "✅  md_whole.xtc already exists for P136 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P136 rep1\n",
      "✅  md_whole.xtc already exists for P136 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P136 rep2\n",
      "✅  md_whole.xtc already exists for P136 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P136 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P137\n",
      "✅  md_whole.xtc already exists for P137 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P137 rep1\n",
      "✅  md_whole.xtc already exists for P137 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P137 rep2\n",
      "✅  md_whole.xtc already exists for P137 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P137 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P138\n",
      "✅  md_whole.xtc already exists for P138 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P138 rep1\n",
      "✅  md_whole.xtc already exists for P138 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P138 rep2\n",
      "✅  md_whole.xtc already exists for P138 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P138 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P139\n",
      "✅  md_whole.xtc already exists for P139 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P139 rep1\n",
      "✅  md_whole.xtc already exists for P139 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P139 rep2\n",
      "✅  md_whole.xtc already exists for P139 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P139 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P140\n",
      "✅  md_whole.xtc already exists for P140 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P140 rep1\n",
      "✅  md_whole.xtc already exists for P140 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P140 rep2\n",
      "✅  md_whole.xtc already exists for P140 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P140 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P141\n",
      "✅  md_whole.xtc already exists for P141 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P141 rep1\n",
      "✅  md_whole.xtc already exists for P141 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P141 rep2\n",
      "✅  md_whole.xtc already exists for P141 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P141 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P142\n",
      "✅  md_whole.xtc already exists for P142 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P142 rep1\n",
      "✅  md_whole.xtc already exists for P142 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P142 rep2\n",
      "✅  md_whole.xtc already exists for P142 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P142 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P143\n",
      "✅  md_whole.xtc already exists for P143 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P143 rep1\n",
      "✅  md_whole.xtc already exists for P143 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P143 rep2\n",
      "✅  md_whole.xtc already exists for P143 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P143 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P144\n",
      "✅  md_whole.xtc already exists for P144 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P144 rep1\n",
      "✅  md_whole.xtc already exists for P144 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P144 rep2\n",
      "✅  md_whole.xtc already exists for P144 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P144 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P145\n",
      "✅  md_whole.xtc already exists for P145 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P145 rep1\n",
      "✅  md_whole.xtc already exists for P145 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P145 rep2\n",
      "✅  md_whole.xtc already exists for P145 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P145 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P146\n",
      "✅  md_whole.xtc already exists for P146 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P146 rep1\n",
      "✅  md_whole.xtc already exists for P146 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P146 rep2\n",
      "✅  md_whole.xtc already exists for P146 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P146 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P147\n",
      "✅  md_whole.xtc already exists for P147 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P147 rep1\n",
      "✅  md_whole.xtc already exists for P147 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P147 rep2\n",
      "✅  md_whole.xtc already exists for P147 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P147 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P148\n",
      "✅  md_whole.xtc already exists for P148 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P148 rep1\n",
      "✅  md_whole.xtc already exists for P148 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P148 rep2\n",
      "✅  md_whole.xtc already exists for P148 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P148 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P149\n",
      "✅  md_whole.xtc already exists for P149 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P149 rep1\n",
      "✅  md_whole.xtc already exists for P149 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P149 rep2\n",
      "✅  md_whole.xtc already exists for P149 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P149 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P150\n",
      "\n",
      "📂 Processing P150 — md_rep1...\n",
      "\n",
      "ERROR:\n",
      "                :-) GROMACS - gmx make_ndx, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P150/md_rep1\n",
      "Command line:\n",
      "  gmx make_ndx -f md.tpr -o index.ndx\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx make_ndx, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -f\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P150/md_rep1\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md.trr -o md_nojump.xtc -pbc nojump\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md.trr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P150/md_rep1\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md_nojump.xtc -o md_center.xtc -center -pbc mol\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md_nojump.xtc' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P150/md_rep1\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md_center.xtc -o md_whole.xtc -pbc whole\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md_center.xtc' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "❌ ERROR: Failed to load trajectory for P150 rep1: [Errno 2] No such file or directory: '/Users/Mohammed/Desktop/SMALLMOL_MD/P150/md_rep1/md.tpr'\n",
      "\n",
      "📂 Processing P150 — md_rep2...\n",
      "\n",
      "ERROR:\n",
      "                :-) GROMACS - gmx make_ndx, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P150/md_rep2\n",
      "Command line:\n",
      "  gmx make_ndx -f md.tpr -o index.ndx\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx make_ndx, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -f\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P150/md_rep2\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md.trr -o md_nojump.xtc -pbc nojump\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md.trr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P150/md_rep2\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md_nojump.xtc -o md_center.xtc -center -pbc mol\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md_nojump.xtc' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P150/md_rep2\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md_center.xtc -o md_whole.xtc -pbc whole\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md_center.xtc' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "❌ ERROR: Failed to load trajectory for P150 rep2: [Errno 2] No such file or directory: '/Users/Mohammed/Desktop/SMALLMOL_MD/P150/md_rep2/md.tpr'\n",
      "\n",
      "📂 Processing P150 — md_rep3...\n",
      "\n",
      "ERROR:\n",
      "                :-) GROMACS - gmx make_ndx, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P150/md_rep3\n",
      "Command line:\n",
      "  gmx make_ndx -f md.tpr -o index.ndx\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx make_ndx, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -f\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P150/md_rep3\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md.trr -o md_nojump.xtc -pbc nojump\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md.trr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P150/md_rep3\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md_nojump.xtc -o md_center.xtc -center -pbc mol\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md_nojump.xtc' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P150/md_rep3\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md_center.xtc -o md_whole.xtc -pbc whole\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md_center.xtc' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "❌ ERROR: Failed to load trajectory for P150 rep3: [Errno 2] No such file or directory: '/Users/Mohammed/Desktop/SMALLMOL_MD/P150/md_rep3/md.tpr'\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P151\n",
      "✅  md_whole.xtc already exists for P151 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P151 rep1\n",
      "✅  md_whole.xtc already exists for P151 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P151 rep2\n",
      "✅  md_whole.xtc already exists for P151 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P151 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P152\n",
      "✅  md_whole.xtc already exists for P152 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P152 rep1\n",
      "✅  md_whole.xtc already exists for P152 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P152 rep2\n",
      "✅  md_whole.xtc already exists for P152 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P152 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P153\n",
      "✅  md_whole.xtc already exists for P153 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P153 rep1\n",
      "✅  md_whole.xtc already exists for P153 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P153 rep2\n",
      "✅  md_whole.xtc already exists for P153 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P153 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P154\n",
      "✅  md_whole.xtc already exists for P154 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P154 rep1\n",
      "✅  md_whole.xtc already exists for P154 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P154 rep2\n",
      "✅  md_whole.xtc already exists for P154 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P154 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P155\n",
      "✅  md_whole.xtc already exists for P155 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P155 rep1\n",
      "✅  md_whole.xtc already exists for P155 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P155 rep2\n",
      "✅  md_whole.xtc already exists for P155 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P155 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P156\n",
      "✅  md_whole.xtc already exists for P156 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P156 rep1\n",
      "✅  md_whole.xtc already exists for P156 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P156 rep2\n",
      "✅  md_whole.xtc already exists for P156 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P156 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P157\n",
      "✅  md_whole.xtc already exists for P157 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P157 rep1\n",
      "✅  md_whole.xtc already exists for P157 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P157 rep2\n",
      "✅  md_whole.xtc already exists for P157 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P157 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P158\n",
      "✅  md_whole.xtc already exists for P158 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P158 rep1\n",
      "✅  md_whole.xtc already exists for P158 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P158 rep2\n",
      "✅  md_whole.xtc already exists for P158 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P158 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P159\n",
      "✅  md_whole.xtc already exists for P159 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P159 rep1\n",
      "✅  md_whole.xtc already exists for P159 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P159 rep2\n",
      "✅  md_whole.xtc already exists for P159 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P159 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P160\n",
      "✅  md_whole.xtc already exists for P160 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P160 rep1\n",
      "✅  md_whole.xtc already exists for P160 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P160 rep2\n",
      "✅  md_whole.xtc already exists for P160 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P160 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P161\n",
      "✅  md_whole.xtc already exists for P161 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P161 rep1\n",
      "✅  md_whole.xtc already exists for P161 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P161 rep2\n",
      "✅  md_whole.xtc already exists for P161 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P161 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P162\n",
      "✅  md_whole.xtc already exists for P162 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P162 rep1\n",
      "✅  md_whole.xtc already exists for P162 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P162 rep2\n",
      "✅  md_whole.xtc already exists for P162 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P162 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P163\n",
      "✅  md_whole.xtc already exists for P163 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P163 rep1\n",
      "✅  md_whole.xtc already exists for P163 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P163 rep2\n",
      "✅  md_whole.xtc already exists for P163 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P163 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P164\n",
      "✅  md_whole.xtc already exists for P164 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P164 rep1\n",
      "✅  md_whole.xtc already exists for P164 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P164 rep2\n",
      "✅  md_whole.xtc already exists for P164 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P164 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P165\n",
      "✅  md_whole.xtc already exists for P165 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P165 rep1\n",
      "✅  md_whole.xtc already exists for P165 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P165 rep2\n",
      "✅  md_whole.xtc already exists for P165 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P165 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P166\n",
      "✅  md_whole.xtc already exists for P166 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P166 rep1\n",
      "✅  md_whole.xtc already exists for P166 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P166 rep2\n",
      "✅  md_whole.xtc already exists for P166 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P166 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P167\n",
      "✅  md_whole.xtc already exists for P167 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P167 rep1\n",
      "✅  md_whole.xtc already exists for P167 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P167 rep2\n",
      "✅  md_whole.xtc already exists for P167 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P167 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P168\n",
      "✅  md_whole.xtc already exists for P168 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P168 rep1\n",
      "✅  md_whole.xtc already exists for P168 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P168 rep2\n",
      "✅  md_whole.xtc already exists for P168 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P168 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P169\n",
      "\n",
      "📂 Processing P169 — md_rep1...\n",
      "\n",
      "ERROR:\n",
      "                :-) GROMACS - gmx make_ndx, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P169/md_rep1\n",
      "Command line:\n",
      "  gmx make_ndx -f md.tpr -o index.ndx\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx make_ndx, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -f\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P169/md_rep1\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md.trr -o md_nojump.xtc -pbc nojump\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md.trr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P169/md_rep1\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md_nojump.xtc -o md_center.xtc -center -pbc mol\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md_nojump.xtc' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P169/md_rep1\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md_center.xtc -o md_whole.xtc -pbc whole\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md_center.xtc' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "❌ ERROR: Failed to load trajectory for P169 rep1: [Errno 2] No such file or directory: '/Users/Mohammed/Desktop/SMALLMOL_MD/P169/md_rep1/md.tpr'\n",
      "\n",
      "📂 Processing P169 — md_rep2...\n",
      "\n",
      "ERROR:\n",
      "                :-) GROMACS - gmx make_ndx, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P169/md_rep2\n",
      "Command line:\n",
      "  gmx make_ndx -f md.tpr -o index.ndx\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx make_ndx, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -f\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P169/md_rep2\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md.trr -o md_nojump.xtc -pbc nojump\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md.trr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P169/md_rep2\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md_nojump.xtc -o md_center.xtc -center -pbc mol\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md_nojump.xtc' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P169/md_rep2\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md_center.xtc -o md_whole.xtc -pbc whole\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md_center.xtc' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "❌ ERROR: Failed to load trajectory for P169 rep2: [Errno 2] No such file or directory: '/Users/Mohammed/Desktop/SMALLMOL_MD/P169/md_rep2/md.tpr'\n",
      "\n",
      "📂 Processing P169 — md_rep3...\n",
      "\n",
      "ERROR:\n",
      "                :-) GROMACS - gmx make_ndx, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P169/md_rep3\n",
      "Command line:\n",
      "  gmx make_ndx -f md.tpr -o index.ndx\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx make_ndx, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -f\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P169/md_rep3\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md.trr -o md_nojump.xtc -pbc nojump\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md.trr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P169/md_rep3\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md_nojump.xtc -o md_center.xtc -center -pbc mol\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md_nojump.xtc' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "ERROR:\n",
      "                 :-) GROMACS - gmx trjconv, 2025.1-Homebrew (-:\n",
      "\n",
      "Executable:   /opt/homebrew/bin/../Cellar/gromacs/2025.1/bin/gmx\n",
      "Data prefix:  /opt/homebrew/bin/../Cellar/gromacs/2025.1\n",
      "Working dir:  /Users/mohammed/Desktop/SMALLMOL_MD/P169/md_rep3\n",
      "Command line:\n",
      "  gmx trjconv -s md.tpr -f md_center.xtc -o md_whole.xtc -pbc whole\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Program:     gmx trjconv, version 2025.1-Homebrew\n",
      "Source file: src/gromacs/commandline/cmdlineparser.cpp (line 271)\n",
      "Function:    void gmx::CommandLineParser::parse(int*, char**)\n",
      "\n",
      "Error in user input:\n",
      "Invalid command-line options\n",
      "  In command-line option -s\n",
      "    File 'md.tpr' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "  In command-line option -f\n",
      "    File 'md_center.xtc' does not exist or is not accessible.\n",
      "    The file could not be opened.\n",
      "      Reason: No such file or directory\n",
      "      (call to fopen() returned error code 2)\n",
      "\n",
      "For more information and tips for troubleshooting, please check the GROMACS\n",
      "website at https://manual.gromacs.org/current/user-guide/run-time-errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "❌ ERROR: Failed to load trajectory for P169 rep3: [Errno 2] No such file or directory: '/Users/Mohammed/Desktop/SMALLMOL_MD/P169/md_rep3/md.tpr'\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P170\n",
      "✅  md_whole.xtc already exists for P170 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P170 rep1\n",
      "✅  md_whole.xtc already exists for P170 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P170 rep2\n",
      "✅  md_whole.xtc already exists for P170 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P170 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P171\n",
      "✅  md_whole.xtc already exists for P171 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P171 rep1\n",
      "✅  md_whole.xtc already exists for P171 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P171 rep2\n",
      "✅  md_whole.xtc already exists for P171 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P171 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P172\n",
      "✅  md_whole.xtc already exists for P172 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P172 rep1\n",
      "✅  md_whole.xtc already exists for P172 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P172 rep2\n",
      "✅  md_whole.xtc already exists for P172 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P172 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P173\n",
      "✅  md_whole.xtc already exists for P173 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P173 rep1\n",
      "✅  md_whole.xtc already exists for P173 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P173 rep2\n",
      "✅  md_whole.xtc already exists for P173 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P173 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P174\n",
      "✅  md_whole.xtc already exists for P174 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P174 rep1\n",
      "✅  md_whole.xtc already exists for P174 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P174 rep2\n",
      "✅  md_whole.xtc already exists for P174 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P174 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P175\n",
      "✅  md_whole.xtc already exists for P175 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P175 rep1\n",
      "✅  md_whole.xtc already exists for P175 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P175 rep2\n",
      "✅  md_whole.xtc already exists for P175 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P175 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P176\n",
      "✅  md_whole.xtc already exists for P176 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P176 rep1\n",
      "✅  md_whole.xtc already exists for P176 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P176 rep2\n",
      "✅  md_whole.xtc already exists for P176 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P176 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P177\n",
      "✅  md_whole.xtc already exists for P177 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P177 rep1\n",
      "✅  md_whole.xtc already exists for P177 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P177 rep2\n",
      "✅  md_whole.xtc already exists for P177 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P177 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P178\n",
      "✅  md_whole.xtc already exists for P178 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P178 rep1\n",
      "✅  md_whole.xtc already exists for P178 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P178 rep2\n",
      "✅  md_whole.xtc already exists for P178 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P178 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P179\n",
      "✅  md_whole.xtc already exists for P179 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P179 rep1\n",
      "✅  md_whole.xtc already exists for P179 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P179 rep2\n",
      "✅  md_whole.xtc already exists for P179 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P179 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P180\n",
      "✅  md_whole.xtc already exists for P180 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P180 rep1\n",
      "✅  md_whole.xtc already exists for P180 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P180 rep2\n",
      "✅  md_whole.xtc already exists for P180 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P180 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P181\n",
      "✅  md_whole.xtc already exists for P181 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P181 rep1\n",
      "✅  md_whole.xtc already exists for P181 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P181 rep2\n",
      "✅  md_whole.xtc already exists for P181 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P181 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P182\n",
      "✅  md_whole.xtc already exists for P182 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P182 rep1\n",
      "✅  md_whole.xtc already exists for P182 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P182 rep2\n",
      "✅  md_whole.xtc already exists for P182 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P182 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P183\n",
      "✅  md_whole.xtc already exists for P183 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P183 rep1\n",
      "✅  md_whole.xtc already exists for P183 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P183 rep2\n",
      "✅  md_whole.xtc already exists for P183 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P183 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P184\n",
      "✅  md_whole.xtc already exists for P184 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P184 rep1\n",
      "✅  md_whole.xtc already exists for P184 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P184 rep2\n",
      "✅  md_whole.xtc already exists for P184 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P184 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P185\n",
      "✅  md_whole.xtc already exists for P185 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P185 rep1\n",
      "✅  md_whole.xtc already exists for P185 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P185 rep2\n",
      "✅  md_whole.xtc already exists for P185 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P185 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P186\n",
      "✅  md_whole.xtc already exists for P186 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P186 rep1\n",
      "✅  md_whole.xtc already exists for P186 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P186 rep2\n",
      "✅  md_whole.xtc already exists for P186 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P186 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P187\n",
      "✅  md_whole.xtc already exists for P187 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P187 rep1\n",
      "✅  md_whole.xtc already exists for P187 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P187 rep2\n",
      "✅  md_whole.xtc already exists for P187 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P187 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P188\n",
      "✅  md_whole.xtc already exists for P188 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P188 rep1\n",
      "✅  md_whole.xtc already exists for P188 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P188 rep2\n",
      "✅  md_whole.xtc already exists for P188 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P188 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P189\n",
      "✅  md_whole.xtc already exists for P189 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P189 rep1\n",
      "✅  md_whole.xtc already exists for P189 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P189 rep2\n",
      "✅  md_whole.xtc already exists for P189 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P189 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P190\n",
      "✅  md_whole.xtc already exists for P190 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P190 rep1\n",
      "✅  md_whole.xtc already exists for P190 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P190 rep2\n",
      "✅  md_whole.xtc already exists for P190 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P190 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P191\n",
      "✅  md_whole.xtc already exists for P191 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P191 rep1\n",
      "✅  md_whole.xtc already exists for P191 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P191 rep2\n",
      "✅  md_whole.xtc already exists for P191 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P191 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P192\n",
      "✅  md_whole.xtc already exists for P192 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P192 rep1\n",
      "✅  md_whole.xtc already exists for P192 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P192 rep2\n",
      "✅  md_whole.xtc already exists for P192 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P192 rep3\n",
      "/Users/Mohammed/Desktop/SMALLMOL_MD/P193\n",
      "✅  md_whole.xtc already exists for P193 rep1, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P193 rep1\n",
      "✅  md_whole.xtc already exists for P193 rep2, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P193 rep2\n",
      "✅  md_whole.xtc already exists for P193 rep3, skipping GROMACS post-processing...\n",
      "✅ Collected analysis for P193 rep3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from subprocess import run\n",
    "import MDAnalysis as mda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from MDAnalysis.analysis import distances\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem.rdmolfiles import MolFromPDBFile\n",
    "\n",
    "results = [] # Data storehouse\n",
    "\n",
    "# 📥 Read SMALLMOL IDs from second column\n",
    "csv_file = \"SMALLMOL_SMILES_LIST.csv\"\n",
    "try:\n",
    "    mol_df = pd.read_csv(csv_file, encoding=\"utf-8\")\n",
    "    cid_list = mol_df.iloc[:, 1].dropna().astype(str).tolist()\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ ERROR: File 'SMALLMOL_SMILES_LIST.csv' not found!\")\n",
    "    exit()\n",
    "\n",
    "def run_cmd(command, input_text=\"0\", cwd=None):\n",
    "    result = run(f\"echo {input_text} | {command}\", shell=True, cwd=cwd, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"ERROR:\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(\"INFO:\")\n",
    "        print(result.stdout)\n",
    "\n",
    "for cid in cid_list:\n",
    "    base_dir = f\"/Users/Mohammed/Desktop/SMALLMOL_MD/P{cid}\"\n",
    "    print(base_dir)\n",
    "\n",
    "    if not os.path.exists(base_dir):\n",
    "        print(f\"⚠️  SMALLMOL {cid} directory not found, skipping...\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    for rep in range(1, 4):\n",
    "        rep_dir = os.path.join(base_dir, f\"md_rep{rep}\")\n",
    "        if not os.path.exists(rep_dir):\n",
    "            print(f\"⚠️  {rep_dir} not found, skipping...\")\n",
    "            continue\n",
    "\n",
    "        xtc_path = os.path.join(rep_dir, \"md_whole.xtc\")\n",
    "        tpr_path = os.path.join(rep_dir, \"md.tpr\")\n",
    "\n",
    "        if os.path.exists(xtc_path):\n",
    "            print(f\"✅  md_whole.xtc already exists for P{cid} rep{rep}, skipping GROMACS post-processing...\")\n",
    "        else:\n",
    "            print(f\"\\n📂 Processing P{cid} — md_rep{rep}...\\n\")\n",
    "\n",
    "            # Step 1: Index creation\n",
    "            run_cmd(\"gmx make_ndx -f md.tpr -o index.ndx\", input_text=\"q\", cwd=rep_dir)\n",
    "\n",
    "            # Step 2: Remove PBC jumps\n",
    "            run_cmd(\"gmx trjconv -s md.tpr -f md.trr -o md_nojump.xtc -pbc nojump\", input_text=\"0\", cwd=rep_dir)\n",
    "\n",
    "            # Step 3: Center on UNL but keep all atoms\n",
    "            run_cmd(\"gmx trjconv -s md.tpr -f md_nojump.xtc -o md_center.xtc -center -pbc mol\", input_text=\"2 0\", cwd=rep_dir)\n",
    "\n",
    "            # Step 4: Make molecule whole\n",
    "            run_cmd(\"gmx trjconv -s md.tpr -f md_center.xtc -o md_whole.xtc -pbc whole\", input_text=\"0\", cwd=rep_dir)\n",
    "\n",
    "        # Step 5: Load trajectory\n",
    "        try:\n",
    "            u = mda.Universe(tpr_path, xtc_path)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ ERROR: Failed to load trajectory for P{cid} rep{rep}: {e}\")\n",
    "            continue\n",
    "\n",
    "        ligand = u.select_atoms(\"resname UNL\")\n",
    "\n",
    "        lengths, rgs, areas, tpsa_values = [], [], [], []\n",
    "        rmsds, com_xs, com_ys, com_zs = [], [], [], []\n",
    "\n",
    "        ref_positions = ligand.positions.copy()\n",
    "\n",
    "        #Save a frame to PDB for TPSA\n",
    "        try:\n",
    "            u.trajectory[0]\n",
    "            frame_pdb = os.path.join(rep_dir, \"frame0.pdb\")\n",
    "            ligand.write(frame_pdb)\n",
    "\n",
    "            mol = MolFromPDBFile(frame_pdb, sanitize=False)\n",
    "            mol = Chem.AddHs(mol)\n",
    "            Chem.SanitizeMol(mol)\n",
    "            ref_tpsa = rdMolDescriptors.CalcTPSA(mol)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  TPSA calc failed for P{cid} rep{rep}: {e}\")\n",
    "            ref_tpsa = np.nan\n",
    "\n",
    "        # Frame analysis\n",
    "        for ts in u.trajectory:\n",
    "            try:\n",
    "                D = distances.self_distance_array(ligand.positions)\n",
    "                mol_length = np.max(D)\n",
    "                rg = ligand.radius_of_gyration()\n",
    "                coords = ligand.positions - ligand.positions.mean(axis=0)\n",
    "                _, S, _ = np.linalg.svd(coords)\n",
    "                area = np.pi * S[0] * S[1]\n",
    "                # RMSD calculation (against frame 0)\n",
    "                rmsd = np.sqrt(np.mean(np.sum((ligand.positions - ref_positions) ** 2, axis=1)))\n",
    "                rmsds.append(rmsd)\n",
    "\n",
    "                # Center of mass tracking\n",
    "                com = ligand.center_of_mass()\n",
    "                com_xs.append(com[0])\n",
    "                com_ys.append(com[1])\n",
    "                com_zs.append(com[2])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Frame error: {e}\")\n",
    "                continue\n",
    "\n",
    "            lengths.append(mol_length)\n",
    "            rgs.append(rg)\n",
    "            areas.append(area)\n",
    "            tpsa_values.append(ref_tpsa)\n",
    "\n",
    "        # Compute COM displacement\n",
    "        com_coords = np.column_stack((com_xs, com_ys, com_zs))\n",
    "        disp = com_coords - com_coords[0]\n",
    "        disp_magnitude = np.linalg.norm(disp, axis=1)\n",
    "\n",
    "        # Estimate diffusion coefficient from MSD (linear fit)\n",
    "        try:\n",
    "            msd = np.sum(disp**2, axis=1)\n",
    "            frame_interval_ps = 20  # Based on mdp: 2 fs × 10000 steps\n",
    "            times = np.arange(len(msd)) * frame_interval_ps\n",
    "            from scipy.stats import linregress\n",
    "            slope, _, _, _, _ = linregress(times, msd)\n",
    "            diffusion_coeff = slope / 6  # 3D Einstein relation\n",
    "            diffusion_coeff = diffusion_coeff * 1e-16  # [Å²/ps → cm²/s]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Diffusion coeff calc failed for P{cid} rep{rep}: {e}\")\n",
    "            diffusion_coeff = np.nan\n",
    "\n",
    "        # Save results\n",
    "        df = pd.DataFrame({\n",
    "            \"ID\": cid,\n",
    "            \"rep\": rep,\n",
    "            \"frame\": range(len(lengths)),\n",
    "            \"length\": lengths,\n",
    "            \"rg\": rgs,\n",
    "            \"area\": areas,\n",
    "            \"tpsa\": tpsa_values,\n",
    "            \"rmsd\": rmsds,\n",
    "            \"com_x\": com_xs,\n",
    "            \"com_y\": com_ys,\n",
    "            \"com_z\": com_zs,\n",
    "            \"com_disp\": disp_magnitude,\n",
    "            \"diff_coeff\": [diffusion_coeff] * len(lengths),  # same for all frames\n",
    "        })\n",
    "\n",
    "        results.append(df)\n",
    "        #df.to_csv(output_csv, index=False)\n",
    "        print(f\"✅ Collected analysis for P{cid} rep{rep}\")\n",
    "    \n",
    "final_df = pd.concat(results, ignore_index=True)\n",
    "#final_df.to_csv(\"final_results_1.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"MD_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipping 117 rep 1 — too few frames left\n",
      "❌ Skipping 184 rep 1 — too few frames left\n",
      "❌ Skipping 184 rep 2 — too few frames left\n",
      "❌ Skipping 184 rep 3 — too few frames left\n",
      "❌ Skipping 67 rep 3 — too few frames left\n",
      "✅ Trimming complete. Output saved to 'rg_truncated.csv'\n",
      "Retained 550 replicates. Skipped 5 due to instability.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"MD_results.csv\")\n",
    "df[\"ID\"] = df[\"ID\"].astype(str)  # ensure ID is string for grouping\n",
    "\n",
    "descriptor = \"rg\"\n",
    "threshold = 0.02  # 2% difference tolerance\n",
    "min_frames = 200\n",
    "step = 5  # frames to discard per iteration\n",
    "\n",
    "# Collect cleaned replicates\n",
    "filtered_data = []\n",
    "skipped = []\n",
    "\n",
    "grouped = df.groupby([\"ID\", \"rep\"])\n",
    "\n",
    "for (cid, rep), group in grouped:\n",
    "    working = group.sort_values(\"frame\").copy()\n",
    "\n",
    "    while True:\n",
    "        total_frames = len(working)\n",
    "        if total_frames < min_frames:\n",
    "            print(f\"❌ Skipping {cid} rep {rep} — too few frames left\")\n",
    "            skipped.append((cid, rep))\n",
    "            break\n",
    "\n",
    "        mid = total_frames // 2\n",
    "        first_half = working.iloc[:mid]\n",
    "        last_half = working.iloc[-mid:]\n",
    "\n",
    "        avg_first = first_half[descriptor].mean()\n",
    "        avg_last = last_half[descriptor].mean()\n",
    "        diff_pct = abs(avg_last - avg_first) / avg_last\n",
    "\n",
    "        if diff_pct <= threshold:\n",
    "            filtered_data.append(working)\n",
    "            break\n",
    "        else:\n",
    "            working = working.iloc[step:]\n",
    "\n",
    "# Combine and export\n",
    "rg_truncated = pd.concat(filtered_data, ignore_index=True)\n",
    "rg_truncated.to_csv(\"rg_truncated.csv\", index=False)\n",
    "print(f\"✅ Trimming complete. Output saved to 'rg_truncated.csv'\")\n",
    "print(f\"Retained {len(filtered_data)} replicates. Skipped {len(skipped)} due to instability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipping 117 rep 1 — too few frames left\n",
      "❌ Skipping 171 rep 1 — too few frames left\n",
      "❌ Skipping 184 rep 1 — too few frames left\n",
      "❌ Skipping 184 rep 2 — too few frames left\n",
      "❌ Skipping 184 rep 3 — too few frames left\n",
      "❌ Skipping 27 rep 3 — too few frames left\n",
      "❌ Skipping 52 rep 3 — too few frames left\n",
      "❌ Skipping 67 rep 1 — too few frames left\n",
      "❌ Skipping 67 rep 3 — too few frames left\n",
      "✅ Trimming complete. Output saved to 'length_truncated.csv'\n",
      "Retained 546 replicates. Skipped 9 due to instability.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"MD_results.csv\")\n",
    "df[\"ID\"] = df[\"ID\"].astype(str)  # ensure ID is string for grouping\n",
    "\n",
    "descriptor = \"length\"\n",
    "threshold = 0.02  # 2% difference tolerance\n",
    "min_frames = 200\n",
    "step = 5  # frames to discard per iteration\n",
    "\n",
    "# Collect cleaned replicates\n",
    "filtered_data = []\n",
    "skipped = []\n",
    "\n",
    "grouped = df.groupby([\"ID\", \"rep\"])\n",
    "\n",
    "for (cid, rep), group in grouped:\n",
    "    working = group.sort_values(\"frame\").copy()\n",
    "\n",
    "    while True:\n",
    "        total_frames = len(working)\n",
    "        if total_frames < min_frames:\n",
    "            print(f\"❌ Skipping {cid} rep {rep} — too few frames left\")\n",
    "            skipped.append((cid, rep))\n",
    "            break\n",
    "\n",
    "        mid = total_frames // 2\n",
    "        first_half = working.iloc[:mid]\n",
    "        last_half = working.iloc[-mid:]\n",
    "\n",
    "        avg_first = first_half[descriptor].mean()\n",
    "        avg_last = last_half[descriptor].mean()\n",
    "        diff_pct = abs(avg_last - avg_first) / avg_last\n",
    "\n",
    "        if diff_pct <= threshold:\n",
    "            filtered_data.append(working)\n",
    "            break\n",
    "        else:\n",
    "            working = working.iloc[step:]\n",
    "\n",
    "# Combine and export\n",
    "length_truncated = pd.concat(filtered_data, ignore_index=True)\n",
    "length_truncated.to_csv(\"length_truncated.csv\", index=False)\n",
    "print(f\"✅ Trimming complete. Output saved to 'length_truncated.csv'\")\n",
    "print(f\"Retained {len(filtered_data)} replicates. Skipped {len(skipped)} due to instability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipping 14 rep 2 — too few frames left\n",
      "❌ Skipping 159 rep 2 — too few frames left\n",
      "❌ Skipping 176 rep 3 — too few frames left\n",
      "❌ Skipping 184 rep 1 — too few frames left\n",
      "❌ Skipping 184 rep 2 — too few frames left\n",
      "❌ Skipping 184 rep 3 — too few frames left\n",
      "❌ Skipping 187 rep 3 — too few frames left\n",
      "❌ Skipping 19 rep 1 — too few frames left\n",
      "❌ Skipping 27 rep 2 — too few frames left\n",
      "❌ Skipping 50 rep 3 — too few frames left\n",
      "❌ Skipping 57 rep 2 — too few frames left\n",
      "❌ Skipping 74 rep 3 — too few frames left\n",
      "❌ Skipping 77 rep 3 — too few frames left\n",
      "❌ Skipping 87 rep 1 — too few frames left\n",
      "✅ Trimming complete. Output saved to 'length_truncated.csv'\n",
      "Retained 541 replicates. Skipped 14 due to instability.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"MD_results.csv\")\n",
    "df[\"ID\"] = df[\"ID\"].astype(str)  # ensure ID is string for grouping\n",
    "\n",
    "descriptor = \"rmsd\"\n",
    "threshold = 0.02  # 2% difference tolerance\n",
    "min_frames = 200\n",
    "step = 5  # frames to discard per iteration\n",
    "\n",
    "# Collect cleaned replicates\n",
    "filtered_data = []\n",
    "skipped = []\n",
    "\n",
    "grouped = df.groupby([\"ID\", \"rep\"])\n",
    "\n",
    "for (cid, rep), group in grouped:\n",
    "    working = group.sort_values(\"frame\").copy()\n",
    "\n",
    "    while True:\n",
    "        total_frames = len(working)\n",
    "        if total_frames < min_frames:\n",
    "            print(f\"❌ Skipping {cid} rep {rep} — too few frames left\")\n",
    "            skipped.append((cid, rep))\n",
    "            break\n",
    "\n",
    "        mid = total_frames // 2\n",
    "        first_half = working.iloc[:mid]\n",
    "        last_half = working.iloc[-mid:]\n",
    "\n",
    "        avg_first = first_half[descriptor].mean()\n",
    "        avg_last = last_half[descriptor].mean()\n",
    "        diff_pct = abs(avg_last - avg_first) / avg_last\n",
    "\n",
    "        if diff_pct <= threshold:\n",
    "            filtered_data.append(working)\n",
    "            break\n",
    "        else:\n",
    "            working = working.iloc[step:]\n",
    "\n",
    "# Combine and export\n",
    "rmsd_truncated = pd.concat(filtered_data, ignore_index=True)\n",
    "rmsd_truncated.to_csv(\"rmsd_truncated.csv\", index=False)\n",
    "print(f\"✅ Trimming complete. Output saved to 'length_truncated.csv'\")\n",
    "print(f\"Retained {len(filtered_data)} replicates. Skipped {len(skipped)} due to instability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipping 117 rep 1 — too few frames left\n",
      "❌ Skipping 184 rep 1 — too few frames left\n",
      "❌ Skipping 184 rep 2 — too few frames left\n",
      "❌ Skipping 184 rep 3 — too few frames left\n",
      "❌ Skipping 27 rep 3 — too few frames left\n",
      "❌ Skipping 67 rep 3 — too few frames left\n",
      "❌ Skipping 81 rep 2 — too few frames left\n",
      "✅ Trimming complete. Output saved to 'area_truncated.csv'\n",
      "Retained 548 replicates. Skipped 7 due to instability.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"MD_results.csv\")\n",
    "df[\"ID\"] = df[\"ID\"].astype(str)  # ensure ID is string for grouping\n",
    "\n",
    "descriptor = \"area\"\n",
    "threshold = 0.02  # 2% difference tolerance\n",
    "min_frames = 200\n",
    "step = 5  # frames to discard per iteration\n",
    "\n",
    "# Collect cleaned replicates\n",
    "filtered_data = []\n",
    "skipped = []\n",
    "\n",
    "grouped = df.groupby([\"ID\", \"rep\"])\n",
    "\n",
    "for (cid, rep), group in grouped:\n",
    "    working = group.sort_values(\"frame\").copy()\n",
    "\n",
    "    while True:\n",
    "        total_frames = len(working)\n",
    "        if total_frames < min_frames:\n",
    "            print(f\"❌ Skipping {cid} rep {rep} — too few frames left\")\n",
    "            skipped.append((cid, rep))\n",
    "            break\n",
    "\n",
    "        mid = total_frames // 2\n",
    "        first_half = working.iloc[:mid]\n",
    "        last_half = working.iloc[-mid:]\n",
    "\n",
    "        avg_first = first_half[descriptor].mean()\n",
    "        avg_last = last_half[descriptor].mean()\n",
    "        diff_pct = abs(avg_last - avg_first) / avg_last\n",
    "\n",
    "        if diff_pct <= threshold:\n",
    "            filtered_data.append(working)\n",
    "            break\n",
    "        else:\n",
    "            working = working.iloc[step:]\n",
    "\n",
    "# Combine and export\n",
    "area_truncated = pd.concat(filtered_data, ignore_index=True)\n",
    "area_truncated.to_csv(\"area_truncated.csv\", index=False)\n",
    "print(f\"✅ Trimming complete. Output saved to 'area_truncated.csv'\")\n",
    "print(f\"Retained {len(filtered_data)} replicates. Skipped {len(skipped)} due to instability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipping 122 rep 1 — too few frames left\n",
      "❌ Skipping 123 rep 3 — too few frames left\n",
      "❌ Skipping 176 rep 3 — too few frames left\n",
      "❌ Skipping 184 rep 1 — too few frames left\n",
      "❌ Skipping 184 rep 2 — too few frames left\n",
      "❌ Skipping 184 rep 3 — too few frames left\n",
      "❌ Skipping 27 rep 2 — too few frames left\n",
      "✅ Trimming complete. Output saved to 'com_x_truncated.csv'\n",
      "Retained 548 replicates. Skipped 7 due to instability.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"MD_results.csv\")\n",
    "df[\"ID\"] = df[\"ID\"].astype(str)  # ensure ID is string for grouping\n",
    "\n",
    "descriptor = \"com_x\"\n",
    "threshold = 0.02  # 2% difference tolerance\n",
    "min_frames = 200\n",
    "step = 5  # frames to discard per iteration\n",
    "\n",
    "# Collect cleaned replicates\n",
    "filtered_data = []\n",
    "skipped = []\n",
    "\n",
    "grouped = df.groupby([\"ID\", \"rep\"])\n",
    "\n",
    "for (cid, rep), group in grouped:\n",
    "    working = group.sort_values(\"frame\").copy()\n",
    "\n",
    "    while True:\n",
    "        total_frames = len(working)\n",
    "        if total_frames < min_frames:\n",
    "            print(f\"❌ Skipping {cid} rep {rep} — too few frames left\")\n",
    "            skipped.append((cid, rep))\n",
    "            break\n",
    "\n",
    "        mid = total_frames // 2\n",
    "        first_half = working.iloc[:mid]\n",
    "        last_half = working.iloc[-mid:]\n",
    "\n",
    "        avg_first = first_half[descriptor].mean()\n",
    "        avg_last = last_half[descriptor].mean()\n",
    "        diff_pct = abs(avg_last - avg_first) / avg_last\n",
    "\n",
    "        if diff_pct <= threshold:\n",
    "            filtered_data.append(working)\n",
    "            break\n",
    "        else:\n",
    "            working = working.iloc[step:]\n",
    "\n",
    "# Combine and export\n",
    "com_x_truncated = pd.concat(filtered_data, ignore_index=True)\n",
    "com_x_truncated.to_csv(\"com_x_truncated.csv\", index=False)\n",
    "print(f\"✅ Trimming complete. Output saved to 'com_x_truncated.csv'\")\n",
    "print(f\"Retained {len(filtered_data)} replicates. Skipped {len(skipped)} due to instability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipping 123 rep 3 — too few frames left\n",
      "❌ Skipping 176 rep 3 — too few frames left\n",
      "❌ Skipping 184 rep 1 — too few frames left\n",
      "❌ Skipping 184 rep 2 — too few frames left\n",
      "❌ Skipping 184 rep 3 — too few frames left\n",
      "❌ Skipping 27 rep 2 — too few frames left\n",
      "❌ Skipping 27 rep 3 — too few frames left\n",
      "✅ Trimming complete. Output saved to 'com_y_truncated.csv'\n",
      "Retained 548 replicates. Skipped 7 due to instability.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"MD_results.csv\")\n",
    "df[\"ID\"] = df[\"ID\"].astype(str)  # ensure ID is string for grouping\n",
    "\n",
    "descriptor = \"com_y\"\n",
    "threshold = 0.02  # 2% difference tolerance\n",
    "min_frames = 200\n",
    "step = 5  # frames to discard per iteration\n",
    "\n",
    "# Collect cleaned replicates\n",
    "filtered_data = []\n",
    "skipped = []\n",
    "\n",
    "grouped = df.groupby([\"ID\", \"rep\"])\n",
    "\n",
    "for (cid, rep), group in grouped:\n",
    "    working = group.sort_values(\"frame\").copy()\n",
    "\n",
    "    while True:\n",
    "        total_frames = len(working)\n",
    "        if total_frames < min_frames:\n",
    "            print(f\"❌ Skipping {cid} rep {rep} — too few frames left\")\n",
    "            skipped.append((cid, rep))\n",
    "            break\n",
    "\n",
    "        mid = total_frames // 2\n",
    "        first_half = working.iloc[:mid]\n",
    "        last_half = working.iloc[-mid:]\n",
    "\n",
    "        avg_first = first_half[descriptor].mean()\n",
    "        avg_last = last_half[descriptor].mean()\n",
    "        diff_pct = abs(avg_last - avg_first) / avg_last\n",
    "\n",
    "        if diff_pct <= threshold:\n",
    "            filtered_data.append(working)\n",
    "            break\n",
    "        else:\n",
    "            working = working.iloc[step:]\n",
    "\n",
    "# Combine and export\n",
    "com_y_truncated = pd.concat(filtered_data, ignore_index=True)\n",
    "com_y_truncated.to_csv(\"com_y_truncated.csv\", index=False)\n",
    "print(f\"✅ Trimming complete. Output saved to 'com_y_truncated.csv'\")\n",
    "print(f\"Retained {len(filtered_data)} replicates. Skipped {len(skipped)} due to instability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipping 149 rep 2 — too few frames left\n",
      "❌ Skipping 176 rep 3 — too few frames left\n",
      "❌ Skipping 184 rep 1 — too few frames left\n",
      "❌ Skipping 184 rep 2 — too few frames left\n",
      "❌ Skipping 184 rep 3 — too few frames left\n",
      "❌ Skipping 27 rep 2 — too few frames left\n",
      "❌ Skipping 67 rep 3 — too few frames left\n",
      "✅ Trimming complete. Output saved to 'com_z_truncated.csv'\n",
      "Retained 548 replicates. Skipped 7 due to instability.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"MD_results.csv\")\n",
    "df[\"ID\"] = df[\"ID\"].astype(str)  # ensure ID is string for grouping\n",
    "\n",
    "descriptor = \"com_z\"\n",
    "threshold = 0.02  # 2% difference tolerance\n",
    "min_frames = 200\n",
    "step = 5  # frames to discard per iteration\n",
    "\n",
    "# Collect cleaned replicates\n",
    "filtered_data = []\n",
    "skipped = []\n",
    "\n",
    "grouped = df.groupby([\"ID\", \"rep\"])\n",
    "\n",
    "for (cid, rep), group in grouped:\n",
    "    working = group.sort_values(\"frame\").copy()\n",
    "\n",
    "    while True:\n",
    "        total_frames = len(working)\n",
    "        if total_frames < min_frames:\n",
    "            print(f\"❌ Skipping {cid} rep {rep} — too few frames left\")\n",
    "            skipped.append((cid, rep))\n",
    "            break\n",
    "\n",
    "        mid = total_frames // 2\n",
    "        first_half = working.iloc[:mid]\n",
    "        last_half = working.iloc[-mid:]\n",
    "\n",
    "        avg_first = first_half[descriptor].mean()\n",
    "        avg_last = last_half[descriptor].mean()\n",
    "        diff_pct = abs(avg_last - avg_first) / avg_last\n",
    "\n",
    "        if diff_pct <= threshold:\n",
    "            filtered_data.append(working)\n",
    "            break\n",
    "        else:\n",
    "            working = working.iloc[step:]\n",
    "\n",
    "# Combine and export\n",
    "com_z_truncated = pd.concat(filtered_data, ignore_index=True)\n",
    "com_z_truncated.to_csv(\"com_z_truncated.csv\", index=False)\n",
    "print(f\"✅ Trimming complete. Output saved to 'com_z_truncated.csv'\")\n",
    "print(f\"Retained {len(filtered_data)} replicates. Skipped {len(skipped)} due to instability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipping 184 rep 1 — too few frames left\n",
      "❌ Skipping 184 rep 2 — too few frames left\n",
      "❌ Skipping 184 rep 3 — too few frames left\n",
      "✅ Trimming complete. Output saved to 'tpsa_truncated.csv'\n",
      "Retained 552 replicates. Skipped 3 due to instability.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"MD_results.csv\")\n",
    "df[\"ID\"] = df[\"ID\"].astype(str)  # ensure ID is string for grouping\n",
    "\n",
    "descriptor = \"tpsa\"\n",
    "threshold = 0.02  # 2% difference tolerance\n",
    "min_frames = 200\n",
    "step = 5  # frames to discard per iteration\n",
    "\n",
    "# Collect cleaned replicates\n",
    "filtered_data = []\n",
    "skipped = []\n",
    "\n",
    "grouped = df.groupby([\"ID\", \"rep\"])\n",
    "\n",
    "for (cid, rep), group in grouped:\n",
    "    working = group.sort_values(\"frame\").copy()\n",
    "\n",
    "    while True:\n",
    "        total_frames = len(working)\n",
    "        if total_frames < min_frames:\n",
    "            print(f\"❌ Skipping {cid} rep {rep} — too few frames left\")\n",
    "            skipped.append((cid, rep))\n",
    "            break\n",
    "\n",
    "        mid = total_frames // 2\n",
    "        first_half = working.iloc[:mid]\n",
    "        last_half = working.iloc[-mid:]\n",
    "\n",
    "        avg_first = first_half[descriptor].mean()\n",
    "        avg_last = last_half[descriptor].mean()\n",
    "        diff_pct = abs(avg_last - avg_first) / avg_last\n",
    "\n",
    "        if diff_pct <= threshold:\n",
    "            filtered_data.append(working)\n",
    "            break\n",
    "        else:\n",
    "            working = working.iloc[step:]\n",
    "\n",
    "# Combine and export\n",
    "tpsa_truncated = pd.concat(filtered_data, ignore_index=True)\n",
    "tpsa_truncated.to_csv(\"tpsa_truncated.csv\", index=False)\n",
    "print(f\"✅ Trimming complete. Output saved to 'tpsa_truncated.csv'\")\n",
    "print(f\"Retained {len(filtered_data)} replicates. Skipped {len(skipped)} due to instability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  rep  frame MD_feature      value\n",
      "0  10    1      0     length  18.727976\n",
      "1  10    1      1     length  17.356714\n",
      "2  10    1      2     length  18.580078\n",
      "3  10    1      3     length  17.390956\n",
      "4  10    1      4     length  16.542931\n",
      "(4165136, 5)\n",
      "Unique MD features found:\n",
      "MD_feature\n",
      "tpsa      552552\n",
      "com_z     544028\n",
      "com_y     543298\n",
      "com_x     534623\n",
      "rg        528490\n",
      "area      508423\n",
      "length    501896\n",
      "rmsd      451826\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define files with feature names\n",
    "files = {\n",
    "    \"length\": \"length_truncated.csv\",\n",
    "    \"rg\": \"rg_truncated.csv\",\n",
    "    \"area\": \"area_truncated.csv\",\n",
    "    \"tpsa\": \"tpsa_truncated.csv\",\n",
    "    \"rmsd\": \"rmsd_truncated.csv\",\n",
    "    \"com_x\": \"com_x_truncated.csv\",\n",
    "    \"com_y\": \"com_y_truncated.csv\",\n",
    "    \"com_z\": \"com_z_truncated.csv\"\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for feature, file in files.items():\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Ensure required columns are present\n",
    "    required_cols = [\"ID\", \"rep\", \"frame\"]\n",
    "    value_col = [col for col in df.columns if col not in required_cols][0]\n",
    "\n",
    "    # Rename the value column to 'value'\n",
    "    df = df.rename(columns={value_col: \"value\"})\n",
    "\n",
    "    # Add MD_feature column\n",
    "    df[\"MD_feature\"] = feature\n",
    "\n",
    "    # Append the selected columns only\n",
    "    df_list.append(df[[\"ID\", \"rep\", \"frame\", \"MD_feature\", \"value\"]])\n",
    "\n",
    "# Final vertical concatenation\n",
    "df_final = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Optionally save\n",
    "df_final.to_csv(\"MD_Final.csv\", index=False)\n",
    "\n",
    "print(df_final.head())\n",
    "print(df_final.shape)\n",
    "print(\"Unique MD features found:\")\n",
    "print(features_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load long-form MD data\n",
    "df = pd.read_csv(\"MD_Final.csv\") \n",
    "summary_list = []\n",
    "cid_list = df[\"ID\"].unique().tolist()\n",
    "\n",
    "# Relevant features for computation\n",
    "features_needed = [\"length\", \"rg\", \"area\", \"tpsa\"]\n",
    "\n",
    "# Pivot to simplify per-frame access\n",
    "pivot_df = df[df[\"MD_feature\"].isin(features_needed)].pivot_table(\n",
    "    index=[\"ID\", \"rep\", \"frame\"],\n",
    "    columns=\"MD_feature\",\n",
    "    values=\"value\"\n",
    ").reset_index()\n",
    "\n",
    "for cid in cid_list:\n",
    "    for rep in range(1, 4):\n",
    "        df_rep = pivot_df[(pivot_df[\"ID\"] == cid) & (pivot_df[\"rep\"] == rep)]\n",
    "\n",
    "        if df_rep.empty:\n",
    "            print(f\"⚠️ Skipping ID {cid}, rep {rep} due to missing data\")\n",
    "            continue\n",
    "\n",
    "        window = 200\n",
    "        last_frames = df_rep[df_rep[\"frame\"] >= df_rep[\"frame\"].max() - window]\n",
    "\n",
    "        convergence_score = last_frames[\"rg\"].std() if not last_frames.empty else float('nan')\n",
    "        flexibility_index = df_rep[\"rg\"].std()\n",
    "\n",
    "        folding_index_1 = df_rep[\"rg\"].iloc[0]\n",
    "        folding_index_2 = df_rep[\"rg\"].iloc[50:].mean() if len(df_rep) > 50 else df_rep[\"rg\"].mean()\n",
    "        folding_index_rg = folding_index_1 - folding_index_2\n",
    "\n",
    "        folding_index_l = (\n",
    "            df_rep[\"length\"].iloc[0] - df_rep[\"length\"].iloc[50:].mean()\n",
    "            if len(df_rep) > 50 else df_rep[\"length\"].iloc[0] - df_rep[\"length\"].mean()\n",
    "        )\n",
    "\n",
    "        rep_summary = pd.DataFrame({\n",
    "            \"ID\": [cid],\n",
    "            \"rep\": [rep],\n",
    "            \"mean_length\": [df_rep[\"length\"].mean()],\n",
    "            \"std_length\": [df_rep[\"length\"].std()],\n",
    "            \"min_length\": [df_rep[\"length\"].min()],\n",
    "            \"max_length\": [df_rep[\"length\"].max()],\n",
    "            \"mean_rg\": [df_rep[\"rg\"].mean()],\n",
    "            \"std_rg\": [df_rep[\"rg\"].std()],\n",
    "            \"mean_area\": [df_rep[\"area\"].mean()],\n",
    "            \"std_area\": [df_rep[\"area\"].std()],\n",
    "            \"mean_tpsa\": [df_rep[\"tpsa\"].mean()],\n",
    "            \"std_tpsa\": [df_rep[\"tpsa\"].std()],\n",
    "            \"convergence_score\": [convergence_score],\n",
    "            \"folding_index_rg\": [folding_index_rg],\n",
    "            \"folding_index_l\": [folding_index_l],\n",
    "            \"flexibility_index\": [flexibility_index]\n",
    "        })\n",
    "\n",
    "        summary_list.append(rep_summary)\n",
    "\n",
    "# Combine replicate summaries\n",
    "summary = pd.concat(summary_list, ignore_index=True)\n",
    "\n",
    "# Average over replicates per ID\n",
    "cid_summary = summary.groupby(\"ID\").agg({\n",
    "    \"mean_length\": \"mean\",\n",
    "    \"std_length\": \"mean\",\n",
    "    \"min_length\": \"mean\",\n",
    "    \"max_length\": \"mean\",\n",
    "    \"mean_rg\": \"mean\",\n",
    "    \"std_rg\": \"mean\",\n",
    "    \"mean_area\": \"mean\",\n",
    "    \"std_area\": \"mean\",\n",
    "    \"mean_tpsa\": \"mean\",\n",
    "    \"std_tpsa\": \"mean\",\n",
    "    \"convergence_score\": \"mean\",\n",
    "    \"folding_index_rg\": \"mean\",\n",
    "    \"folding_index_l\": \"mean\",\n",
    "    \"flexibility_index\": \"mean\"\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>smiles</th>\n",
       "      <th>Y</th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean_length</th>\n",
       "      <th>std_length</th>\n",
       "      <th>min_length</th>\n",
       "      <th>max_length</th>\n",
       "      <th>mean_rg</th>\n",
       "      <th>std_rg</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>std_area</th>\n",
       "      <th>mean_tpsa</th>\n",
       "      <th>std_tpsa</th>\n",
       "      <th>convergence_score</th>\n",
       "      <th>folding_index_rg</th>\n",
       "      <th>folding_index_l</th>\n",
       "      <th>flexibility_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>N#Cc1ccc(C(c2ccc(C#N)cc2)n2cncn2)cc1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>bioavailability_ma</td>\n",
       "      <td>13.860008</td>\n",
       "      <td>0.882187</td>\n",
       "      <td>11.547472</td>\n",
       "      <td>15.849547</td>\n",
       "      <td>13.860008</td>\n",
       "      <td>0.882187</td>\n",
       "      <td>13.860008</td>\n",
       "      <td>0.882187</td>\n",
       "      <td>13.860008</td>\n",
       "      <td>0.882187</td>\n",
       "      <td>0.834302</td>\n",
       "      <td>-1.067115</td>\n",
       "      <td>-1.067115</td>\n",
       "      <td>0.882187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>N#Cc1ccc(C(c2ccc(C#N)cc2)n2cncn2)cc1</td>\n",
       "      <td>45.00</td>\n",
       "      <td>half_life_obach</td>\n",
       "      <td>13.860008</td>\n",
       "      <td>0.882187</td>\n",
       "      <td>11.547472</td>\n",
       "      <td>15.849547</td>\n",
       "      <td>13.860008</td>\n",
       "      <td>0.882187</td>\n",
       "      <td>13.860008</td>\n",
       "      <td>0.882187</td>\n",
       "      <td>13.860008</td>\n",
       "      <td>0.882187</td>\n",
       "      <td>0.834302</td>\n",
       "      <td>-1.067115</td>\n",
       "      <td>-1.067115</td>\n",
       "      <td>0.882187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>N#Cc1ccc(C(c2ccc(C#N)cc2)n2cncn2)cc1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>lipophilicity_astrazeneca</td>\n",
       "      <td>13.860008</td>\n",
       "      <td>0.882187</td>\n",
       "      <td>11.547472</td>\n",
       "      <td>15.849547</td>\n",
       "      <td>13.860008</td>\n",
       "      <td>0.882187</td>\n",
       "      <td>13.860008</td>\n",
       "      <td>0.882187</td>\n",
       "      <td>13.860008</td>\n",
       "      <td>0.882187</td>\n",
       "      <td>0.834302</td>\n",
       "      <td>-1.067115</td>\n",
       "      <td>-1.067115</td>\n",
       "      <td>0.882187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>COc1ccc2cc([C@H](C)C(=O)O)ccc2c1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>bioavailability_ma</td>\n",
       "      <td>11.032185</td>\n",
       "      <td>0.353359</td>\n",
       "      <td>9.987534</td>\n",
       "      <td>12.345535</td>\n",
       "      <td>11.049788</td>\n",
       "      <td>0.369715</td>\n",
       "      <td>11.048087</td>\n",
       "      <td>0.366099</td>\n",
       "      <td>11.040256</td>\n",
       "      <td>0.367223</td>\n",
       "      <td>0.333455</td>\n",
       "      <td>0.455290</td>\n",
       "      <td>0.470696</td>\n",
       "      <td>0.369715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>COc1ccc2cc([C@H](C)C(=O)O)ccc2c1</td>\n",
       "      <td>0.13</td>\n",
       "      <td>lipophilicity_astrazeneca</td>\n",
       "      <td>11.032185</td>\n",
       "      <td>0.353359</td>\n",
       "      <td>9.987534</td>\n",
       "      <td>12.345535</td>\n",
       "      <td>11.049788</td>\n",
       "      <td>0.369715</td>\n",
       "      <td>11.048087</td>\n",
       "      <td>0.366099</td>\n",
       "      <td>11.040256</td>\n",
       "      <td>0.367223</td>\n",
       "      <td>0.333455</td>\n",
       "      <td>0.455290</td>\n",
       "      <td>0.470696</td>\n",
       "      <td>0.369715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>189</td>\n",
       "      <td>N[C@@H](Cc1c[nH]c2ccccc12)C(=O)O</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>lipophilicity_astrazeneca</td>\n",
       "      <td>9.215979</td>\n",
       "      <td>0.516819</td>\n",
       "      <td>8.088687</td>\n",
       "      <td>10.627369</td>\n",
       "      <td>9.310864</td>\n",
       "      <td>0.541043</td>\n",
       "      <td>9.307710</td>\n",
       "      <td>0.540521</td>\n",
       "      <td>9.307710</td>\n",
       "      <td>0.540521</td>\n",
       "      <td>0.512765</td>\n",
       "      <td>0.139755</td>\n",
       "      <td>-0.016771</td>\n",
       "      <td>0.541043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>190</td>\n",
       "      <td>CN1C[C@H](C(=O)N[C@]2(C)O[C@@]3(O)[C@@H]4CCCN4...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bbb_martins</td>\n",
       "      <td>17.003216</td>\n",
       "      <td>0.494119</td>\n",
       "      <td>14.631100</td>\n",
       "      <td>19.648101</td>\n",
       "      <td>17.003216</td>\n",
       "      <td>0.494119</td>\n",
       "      <td>16.980123</td>\n",
       "      <td>0.444100</td>\n",
       "      <td>17.003216</td>\n",
       "      <td>0.494119</td>\n",
       "      <td>0.376584</td>\n",
       "      <td>0.036495</td>\n",
       "      <td>0.036495</td>\n",
       "      <td>0.494119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>190</td>\n",
       "      <td>CN1C[C@H](C(=O)N[C@]2(C)O[C@@]3(O)[C@@H]4CCCN4...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bioavailability_ma</td>\n",
       "      <td>17.003216</td>\n",
       "      <td>0.494119</td>\n",
       "      <td>14.631100</td>\n",
       "      <td>19.648101</td>\n",
       "      <td>17.003216</td>\n",
       "      <td>0.494119</td>\n",
       "      <td>16.980123</td>\n",
       "      <td>0.444100</td>\n",
       "      <td>17.003216</td>\n",
       "      <td>0.494119</td>\n",
       "      <td>0.376584</td>\n",
       "      <td>0.036495</td>\n",
       "      <td>0.036495</td>\n",
       "      <td>0.494119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>192</td>\n",
       "      <td>C[C@H]1c2cccc(O)c2C(=O)C2=C(O)[C@]3(O)C(=O)C(C...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>bioavailability_ma</td>\n",
       "      <td>12.993817</td>\n",
       "      <td>0.423772</td>\n",
       "      <td>11.137173</td>\n",
       "      <td>13.951446</td>\n",
       "      <td>12.993817</td>\n",
       "      <td>0.423772</td>\n",
       "      <td>12.993817</td>\n",
       "      <td>0.423772</td>\n",
       "      <td>12.993817</td>\n",
       "      <td>0.423772</td>\n",
       "      <td>0.439441</td>\n",
       "      <td>-0.462445</td>\n",
       "      <td>-0.462445</td>\n",
       "      <td>0.423772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>192</td>\n",
       "      <td>C[C@H]1c2cccc(O)c2C(=O)C2=C(O)[C@]3(O)C(=O)C(C...</td>\n",
       "      <td>14.00</td>\n",
       "      <td>half_life_obach</td>\n",
       "      <td>12.993817</td>\n",
       "      <td>0.423772</td>\n",
       "      <td>11.137173</td>\n",
       "      <td>13.951446</td>\n",
       "      <td>12.993817</td>\n",
       "      <td>0.423772</td>\n",
       "      <td>12.993817</td>\n",
       "      <td>0.423772</td>\n",
       "      <td>12.993817</td>\n",
       "      <td>0.423772</td>\n",
       "      <td>0.439441</td>\n",
       "      <td>-0.462445</td>\n",
       "      <td>-0.462445</td>\n",
       "      <td>0.423772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                             smiles      Y  \\\n",
       "0      2               N#Cc1ccc(C(c2ccc(C#N)cc2)n2cncn2)cc1   1.00   \n",
       "1      2               N#Cc1ccc(C(c2ccc(C#N)cc2)n2cncn2)cc1  45.00   \n",
       "2      2               N#Cc1ccc(C(c2ccc(C#N)cc2)n2cncn2)cc1   1.70   \n",
       "3      3                   COc1ccc2cc([C@H](C)C(=O)O)ccc2c1   1.00   \n",
       "4      3                   COc1ccc2cc([C@H](C)C(=O)O)ccc2c1   0.13   \n",
       "..   ...                                                ...    ...   \n",
       "347  189                   N[C@@H](Cc1c[nH]c2ccccc12)C(=O)O  -1.08   \n",
       "348  190  CN1C[C@H](C(=O)N[C@]2(C)O[C@@]3(O)[C@@H]4CCCN4...   0.00   \n",
       "349  190  CN1C[C@H](C(=O)N[C@]2(C)O[C@@]3(O)[C@@H]4CCCN4...   0.00   \n",
       "350  192  C[C@H]1c2cccc(O)c2C(=O)C2=C(O)[C@]3(O)C(=O)C(C...   1.00   \n",
       "351  192  C[C@H]1c2cccc(O)c2C(=O)C2=C(O)[C@]3(O)C(=O)C(C...  14.00   \n",
       "\n",
       "                       dataset  mean_length  std_length  min_length  \\\n",
       "0           bioavailability_ma    13.860008    0.882187   11.547472   \n",
       "1              half_life_obach    13.860008    0.882187   11.547472   \n",
       "2    lipophilicity_astrazeneca    13.860008    0.882187   11.547472   \n",
       "3           bioavailability_ma    11.032185    0.353359    9.987534   \n",
       "4    lipophilicity_astrazeneca    11.032185    0.353359    9.987534   \n",
       "..                         ...          ...         ...         ...   \n",
       "347  lipophilicity_astrazeneca     9.215979    0.516819    8.088687   \n",
       "348                bbb_martins    17.003216    0.494119   14.631100   \n",
       "349         bioavailability_ma    17.003216    0.494119   14.631100   \n",
       "350         bioavailability_ma    12.993817    0.423772   11.137173   \n",
       "351            half_life_obach    12.993817    0.423772   11.137173   \n",
       "\n",
       "     max_length    mean_rg    std_rg  mean_area  std_area  mean_tpsa  \\\n",
       "0     15.849547  13.860008  0.882187  13.860008  0.882187  13.860008   \n",
       "1     15.849547  13.860008  0.882187  13.860008  0.882187  13.860008   \n",
       "2     15.849547  13.860008  0.882187  13.860008  0.882187  13.860008   \n",
       "3     12.345535  11.049788  0.369715  11.048087  0.366099  11.040256   \n",
       "4     12.345535  11.049788  0.369715  11.048087  0.366099  11.040256   \n",
       "..          ...        ...       ...        ...       ...        ...   \n",
       "347   10.627369   9.310864  0.541043   9.307710  0.540521   9.307710   \n",
       "348   19.648101  17.003216  0.494119  16.980123  0.444100  17.003216   \n",
       "349   19.648101  17.003216  0.494119  16.980123  0.444100  17.003216   \n",
       "350   13.951446  12.993817  0.423772  12.993817  0.423772  12.993817   \n",
       "351   13.951446  12.993817  0.423772  12.993817  0.423772  12.993817   \n",
       "\n",
       "     std_tpsa  convergence_score  folding_index_rg  folding_index_l  \\\n",
       "0    0.882187           0.834302         -1.067115        -1.067115   \n",
       "1    0.882187           0.834302         -1.067115        -1.067115   \n",
       "2    0.882187           0.834302         -1.067115        -1.067115   \n",
       "3    0.367223           0.333455          0.455290         0.470696   \n",
       "4    0.367223           0.333455          0.455290         0.470696   \n",
       "..        ...                ...               ...              ...   \n",
       "347  0.540521           0.512765          0.139755        -0.016771   \n",
       "348  0.494119           0.376584          0.036495         0.036495   \n",
       "349  0.494119           0.376584          0.036495         0.036495   \n",
       "350  0.423772           0.439441         -0.462445        -0.462445   \n",
       "351  0.423772           0.439441         -0.462445        -0.462445   \n",
       "\n",
       "     flexibility_index  \n",
       "0             0.882187  \n",
       "1             0.882187  \n",
       "2             0.882187  \n",
       "3             0.369715  \n",
       "4             0.369715  \n",
       "..                 ...  \n",
       "347           0.541043  \n",
       "348           0.494119  \n",
       "349           0.494119  \n",
       "350           0.423772  \n",
       "351           0.423772  \n",
       "\n",
       "[352 rows x 18 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tdc.single_pred import ADME\n",
    "\n",
    "# Load small molecule ADMET data\n",
    "smallmol = pd.read_csv('SMALLMOL_ADMET.csv')\n",
    "smallmol = smallmol.rename(columns={'compound_ID': 'ID'})\n",
    "smallmol = smallmol[['ID', 'smiles', 'Y', 'dataset']]\n",
    "\n",
    "# Ensure ID is a string in both DataFrames\n",
    "smallmol[\"ID\"] = smallmol[\"ID\"].astype(str)\n",
    "cid_summary[\"ID\"] = cid_summary[\"ID\"].astype(str)  # Assuming you have `cid_summary` already\n",
    "\n",
    "# Filter only molecules present in cid_summary\n",
    "smallmol = smallmol[smallmol[\"ID\"].isin(cid_summary[\"ID\"])]\n",
    "\n",
    "# Merge\n",
    "merged = smallmol.merge(cid_summary, on=\"ID\", how=\"left\")\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"SMALLMOL_MD.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 193/193 [00:02<00:00, 73.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RDKit descriptors saved WITHOUT TPSA\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load SMILES file\n",
    "df = pd.read_csv(\"SMALLMOL_SMILES_LIST.csv\")\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "assert \"smiles\" in df.columns, \"CSV must contain a 'smiles' column\"\n",
    "df[\"ID\"] = df.get(\"compound_ID\", df.index.astype(str))\n",
    "\n",
    "# All RDKit descriptors excluding TPSA\n",
    "descriptor_names = [desc[0] for desc in Descriptors.descList if desc[0] != \"TPSA\"]\n",
    "descriptor_funcs = {name: getattr(Descriptors, name) for name in descriptor_names}\n",
    "\n",
    "# Calculate descriptors\n",
    "results = []\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    mol = Chem.MolFromSmiles(row[\"smiles\"])\n",
    "    if mol is None:\n",
    "        continue\n",
    "    desc_values = {desc: func(mol) for desc, func in descriptor_funcs.items()}\n",
    "    desc_values[\"ID\"] = row[\"ID\"]\n",
    "    desc_values[\"smiles\"] = row[\"smiles\"]\n",
    "    results.append(desc_values)\n",
    "\n",
    "# Save to DataFrame\n",
    "df_rdkit = pd.DataFrame(results)\n",
    "df_rdkit.to_csv(\"SMALLMOL_RDKit.csv\", index=False)\n",
    "print(\"✅ RDKit descriptors saved WITHOUT TPSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged file saved as: SMALLMOL_MD_RDKit_Merged.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both datasets\n",
    "df_md = pd.read_csv(\"SMALLMOL_MD.csv\")\n",
    "df_rdkit = pd.read_csv(\"SMALLMOL_RDKit.csv\")\n",
    "\n",
    "# Standardize ID type\n",
    "df_md[\"ID\"] = df_md[\"ID\"].astype(str)\n",
    "df_rdkit[\"ID\"] = df_rdkit[\"ID\"].astype(str)\n",
    "\n",
    "# If RDKit also has a 'smiles' column, rename it to avoid duplication during merge\n",
    "if \"smiles\" in df_rdkit.columns and \"smiles\" in df_md.columns:\n",
    "    df_rdkit = df_rdkit.drop(columns=[\"smiles\"])  # prefer MD's version\n",
    "\n",
    "# Merge on ID\n",
    "df_merged = pd.merge(df_md, df_rdkit, on=\"ID\", how=\"left\")\n",
    "\n",
    "# Reorder columns: ID, smiles, Y at beginning, rest follow\n",
    "identifier_cols = [col for col in [\"ID\", \"smiles\", \"Y\"] if col in df_merged.columns]\n",
    "other_cols = [col for col in df_merged.columns if col not in identifier_cols]\n",
    "df_merged = df_merged[identifier_cols + other_cols]\n",
    "\n",
    "# Save result\n",
    "df_merged.to_csv(\"SMALLMOL_MD_RDKit_ADMET.csv\", index=False)\n",
    "print(\"✅ Merged file saved as: SMALLMOL_MD_RDKit_Merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧮 Merged DataFrame shape: (352, 227)\n"
     ]
    }
   ],
   "source": [
    "print(\"🧮 Merged DataFrame shape:\", df_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original RDKit features: 202\n",
      "Selected RDKit features: 139\n",
      "Total columns in final DataFrame: 164\n",
      "Top selected RDKit features: ['fr_unbrch_alkane', 'PEOE_VSA1', 'VSA_EState4', 'fr_ether', 'VSA_EState8', 'SlogP_VSA2', 'fr_Nhpyrrole', 'SlogP_VSA8', 'NumHDonors', 'PEOE_VSA10']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"SMALLMOL_MD_RDKit_ADMET.csv\")\n",
    "\n",
    "# Step 1: Define column groups\n",
    "meta_cols = ['ID', 'smiles', 'dataset', 'Y']\n",
    "md_keywords = ['length', 'rg', 'area', 'convergence', 'folding', 'flexibility', 'tpsa']\n",
    "md_cols = [col for col in df.columns if any(k in col.lower() for k in md_keywords)]\n",
    "rdkit_cols = [col for col in df.columns if col not in meta_cols + md_cols]\n",
    "\n",
    "# Step 2: Filter RDKit features and drop NaNs\n",
    "rdkit_df = df[rdkit_cols].dropna()\n",
    "meta_md_df = df.loc[rdkit_df.index, meta_cols + md_cols]\n",
    "y = meta_md_df['Y']\n",
    "\n",
    "# Step 3: Correlation with Y\n",
    "correlation_with_y = rdkit_df.corrwith(y).abs().sort_values(ascending=False)\n",
    "sorted_features = correlation_with_y.index.tolist()\n",
    "\n",
    "# Step 4: Drop RDKit features highly correlated with each other (threshold)\n",
    "threshold = 0.9\n",
    "selected_rdkit = []\n",
    "corr_matrix = rdkit_df[sorted_features].corr().abs()\n",
    "\n",
    "for feature in sorted_features:\n",
    "    if not selected_rdkit:\n",
    "        selected_rdkit.append(feature)\n",
    "    elif all(corr_matrix.loc[feature, selected_rdkit] < threshold):\n",
    "        selected_rdkit.append(feature)\n",
    "\n",
    "# Step 5: Combine metadata, MD, and selected RDKit features\n",
    "final_df = pd.concat([meta_md_df, rdkit_df[selected_rdkit]], axis=1)\n",
    "\n",
    "# Optional: Save\n",
    "# final_df.to_csv(\"MD_RDKit_Selected.csv\", index=False)\n",
    "\n",
    "# Summary\n",
    "print(f\"Original RDKit features: {len(rdkit_cols)}\")\n",
    "print(f\"Selected RDKit features: {len(selected_rdkit)}\")\n",
    "print(f\"Total columns in final DataFrame: {final_df.shape[1]}\")\n",
    "print(\"Top selected RDKit features:\", selected_rdkit[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File saved as 'MD_ADMET_RDKIT_FS.csv' with proper column order.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define preferred column order\n",
    "ordered_cols = ['ID', 'smiles', 'dataset', 'Y']\n",
    "remaining_cols = [col for col in final_df.columns if col not in ordered_cols]\n",
    "final_ordered_df = final_df[ordered_cols + remaining_cols]\n",
    "\n",
    "# Step 2: Save to CSV\n",
    "final_ordered_df.to_csv(\"MD_ADMET_RDKIT_FS.csv\", index=False)\n",
    "\n",
    "print(\"✅ File saved as 'MD_ADMET_RDKIT_FS.csv' with proper column order.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule</th>\n",
       "      <th>Replicate</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Performance_ns_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue Jul 8 23:56:15 2025</td>\n",
       "      <td>Wed Jul 9 01:43:09 2025</td>\n",
       "      <td>01:46:54</td>\n",
       "      <td>269.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>2</td>\n",
       "      <td>Tue Jul 8 23:58:02 2025</td>\n",
       "      <td>Wed Jul 9 01:39:24 2025</td>\n",
       "      <td>01:41:22</td>\n",
       "      <td>284.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>3</td>\n",
       "      <td>Wed Jul 9 00:27:36 2025</td>\n",
       "      <td>Wed Jul 9 01:53:07 2025</td>\n",
       "      <td>01:25:31</td>\n",
       "      <td>336.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed Jul 9 01:42:29 2025</td>\n",
       "      <td>Wed Jul 9 03:08:26 2025</td>\n",
       "      <td>01:25:57</td>\n",
       "      <td>335.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jul 9 01:46:16 2025</td>\n",
       "      <td>Wed Jul 9 03:11:36 2025</td>\n",
       "      <td>01:25:20</td>\n",
       "      <td>337.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "      <td>Fri Jul 18 19:20:43 2025</td>\n",
       "      <td>Fri Jul 18 21:04:33 2025</td>\n",
       "      <td>01:43:50</td>\n",
       "      <td>277.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>192</td>\n",
       "      <td>3</td>\n",
       "      <td>Fri Jul 18 21:13:26 2025</td>\n",
       "      <td>Fri Jul 18 22:59:37 2025</td>\n",
       "      <td>01:46:11</td>\n",
       "      <td>271.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Jul 18 23:07:40 2025</td>\n",
       "      <td>Sat Jul 19 00:30:39 2025</td>\n",
       "      <td>01:22:59</td>\n",
       "      <td>347.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jul 19 00:37:21 2025</td>\n",
       "      <td>Sat Jul 19 02:21:13 2025</td>\n",
       "      <td>01:43:52</td>\n",
       "      <td>277.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>Sat Jul 19 02:25:13 2025</td>\n",
       "      <td>Sat Jul 19 04:07:49 2025</td>\n",
       "      <td>01:42:36</td>\n",
       "      <td>280.733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Molecule Replicate                     Start                       End  \\\n",
       "0        134         1   Tue Jul 8 23:56:15 2025   Wed Jul 9 01:43:09 2025   \n",
       "1        134         2   Tue Jul 8 23:58:02 2025   Wed Jul 9 01:39:24 2025   \n",
       "2        134         3   Wed Jul 9 00:27:36 2025   Wed Jul 9 01:53:07 2025   \n",
       "3        135         1   Wed Jul 9 01:42:29 2025   Wed Jul 9 03:08:26 2025   \n",
       "4        135         2   Wed Jul 9 01:46:16 2025   Wed Jul 9 03:11:36 2025   \n",
       "..       ...       ...                       ...                       ...   \n",
       "169      192         2  Fri Jul 18 19:20:43 2025  Fri Jul 18 21:04:33 2025   \n",
       "170      192         3  Fri Jul 18 21:13:26 2025  Fri Jul 18 22:59:37 2025   \n",
       "171      193         1  Fri Jul 18 23:07:40 2025  Sat Jul 19 00:30:39 2025   \n",
       "172      193         2  Sat Jul 19 00:37:21 2025  Sat Jul 19 02:21:13 2025   \n",
       "173      193         3  Sat Jul 19 02:25:13 2025  Sat Jul 19 04:07:49 2025   \n",
       "\n",
       "     Duration Performance_ns_day  \n",
       "0    01:46:54            269.406  \n",
       "1    01:41:22            284.135  \n",
       "2    01:25:31            336.763  \n",
       "3    01:25:57            335.085  \n",
       "4    01:25:20            337.534  \n",
       "..        ...                ...  \n",
       "169  01:43:50            277.359  \n",
       "170  01:46:11            271.209  \n",
       "171  01:22:59            347.075  \n",
       "172  01:43:52            277.270  \n",
       "173  01:42:36            280.733  \n",
       "\n",
       "[174 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved CSV → simulation_times.csv\n",
      "\n",
      "[AVERAGES]\n",
      "Overall average duration (completed only): 1:34:54\n",
      "Per-molecule average durations (completed only):\n",
      "  134: 1:37:56\n",
      "  135: 1:32:03\n",
      "  136: 1:29:34\n",
      "  137: 1:25:34\n",
      "  138: 1:29:38\n",
      "  139: 1:32:28\n",
      "  140: 1:52:27\n",
      "  141: 1:24:00\n",
      "  142: 1:42:49\n",
      "  143: 1:36:51\n",
      "  144: 1:19:04\n",
      "  145: 1:46:56\n",
      "  146: 1:21:20\n",
      "  147: 1:15:04\n",
      "  148: 1:23:57\n",
      "  149: 1:31:56\n",
      "  151: 1:30:14\n",
      "  152: 1:37:34\n",
      "  153: 1:25:51\n",
      "  154: 1:39:31\n",
      "  155: 1:43:08\n",
      "  156: 1:43:39\n",
      "  157: 1:39:46\n",
      "  158: 1:24:16\n",
      "  159: 1:34:12\n",
      "  160: 1:27:21\n",
      "  161: 1:42:40\n",
      "  162: 1:43:52\n",
      "  163: 1:23:54\n",
      "  164: 1:36:56\n",
      "  165: 1:47:06\n",
      "  166: 1:30:00\n",
      "  167: 1:26:44\n",
      "  168: 1:45:58\n",
      "  170: 1:43:15\n",
      "  171: 1:34:23\n",
      "  172: 1:28:59\n",
      "  173: 1:24:25\n",
      "  174: 1:42:28\n",
      "  175: 1:39:44\n",
      "  176: 1:31:10\n",
      "  177: 1:35:17\n",
      "  178: 1:38:12\n",
      "  179: 1:49:59\n",
      "  180: 1:24:53\n",
      "  181: 1:36:23\n",
      "  182: 1:44:27\n",
      "  183: 1:38:24\n",
      "  185: 1:25:02\n",
      "  186: 1:39:07\n",
      "  187: 1:44:20\n",
      "  188: 1:53:51\n",
      "  189: 1:30:44\n",
      "  190: 1:37:41\n",
      "  191: 1:20:55\n",
      "  192: 1:44:34\n",
      "  193: 1:36:29\n"
     ]
    }
   ],
   "source": [
    "# --- Parse MD run summary text → table (+ averages) --------------------------\n",
    "# Works in Jupyter. Paste your text into DATA below, or set DATA=None and\n",
    "# provide a file path in DATA_FILE.\n",
    "\n",
    "from __future__ import annotations\n",
    "import csv\n",
    "import io\n",
    "import re\n",
    "from datetime import timedelta\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    HAVE_PANDAS = True\n",
    "except Exception:\n",
    "    HAVE_PANDAS = False\n",
    "\n",
    "# === INPUT ==================================================================\n",
    "# Option A: paste your text between the triple quotes:\n",
    "DATA = \"\"\"<134    1       Tue Jul  8 23:56:15 2025 Wed Jul  9 01:43:09 2025   01:46:54        269.406\n",
    "134    2       Tue Jul  8 23:58:02 2025 Wed Jul  9 01:39:24 2025   01:41:22        284.135\n",
    "134    3       Wed Jul  9 00:27:36 2025 Wed Jul  9 01:53:07 2025   01:25:31        336.763\n",
    "135    1       Wed Jul  9 01:42:29 2025 Wed Jul  9 03:08:26 2025   01:25:57        335.085\n",
    "135    2       Wed Jul  9 01:46:16 2025 Wed Jul  9 03:11:36 2025   01:25:20        337.534\n",
    "135    3       Wed Jul  9 01:57:29 2025 Wed Jul  9 03:42:20 2025   01:44:51        274.652\n",
    "136    1       Wed Jul  9 03:12:08 2025 Wed Jul  9 04:34:24 2025   01:22:16        350.038\n",
    "136    2       Wed Jul  9 03:15:14 2025 Wed Jul  9 04:38:45 2025   01:23:31        344.842\n",
    "136    3       Wed Jul  9 03:45:37 2025 Wed Jul  9 05:28:32 2025   01:42:55        279.872\n",
    "137    1       Wed Jul  9 04:44:03 2025 Wed Jul  9 06:08:21 2025   01:24:18        341.601\n",
    "137    2       Wed Jul  9 04:50:34 2025 Wed Jul  9 06:14:10 2025   01:23:36        344.514\n",
    "137    3       Wed Jul  9 05:33:04 2025 Wed Jul  9 07:01:51 2025   01:28:47        324.373\n",
    "138    1       Wed Jul  9 06:13:13 2025 Wed Jul  9 07:36:00 2025   01:22:47        347.909\n",
    "138    2       Wed Jul  9 06:18:15 2025 Wed Jul  9 07:42:03 2025   01:23:48        343.654\n",
    "138    3       Wed Jul  9 07:47:43 2025 Wed Jul  9 09:30:03 2025   01:42:20        281.447\n",
    "139    1       Wed Jul  9 08:34:45 2025 Wed Jul  9 10:24:33 2025   01:49:48        262.320\n",
    "139    2       Wed Jul  9 10:30:37 2025 Wed Jul  9 11:55:08 2025   01:24:31        340.762\n",
    "139    3       Wed Jul  9 11:59:23 2025 Wed Jul  9 13:22:29 2025   01:23:06        346.563\n",
    "140    1       Wed Jul  9 13:26:29 2025 Wed Jul  9 15:26:58 2025   02:00:29        239.026\n",
    "140    2       Wed Jul  9 17:22:42 2025 Wed Jul  9 19:01:38 2025   01:38:56        291.107\n",
    "140    3       Wed Jul  9 19:06:40 2025 Wed Jul  9 21:04:35 2025   01:57:55        244.267\n",
    "141    1       Wed Jul  9 21:09:37 2025 Wed Jul  9 22:33:49 2025   01:24:12        342.052\n",
    "141    2       Wed Jul  9 22:36:52 2025 Thu Jul 10 00:00:36 2025   01:23:44        343.935\n",
    "141    3       Thu Jul 10 00:04:52 2025 Thu Jul 10 01:28:57 2025   01:24:05        342.549\n",
    "142    1       Thu Jul 10 01:32:55 2025 Thu Jul 10 03:18:10 2025   01:45:15        273.623\n",
    "142    2       Thu Jul 10 03:23:44 2025 Thu Jul 10 05:04:31 2025   01:40:47        285.769\n",
    "142    3       Thu Jul 10 05:09:43 2025 Thu Jul 10 06:52:08 2025   01:42:25        281.223\n",
    "143    1       Thu Jul 10 06:57:24 2025 Thu Jul 10 08:29:03 2025   01:31:39        314.232\n",
    "143    2       Thu Jul 10 07:50:51 2025 Thu Jul 10 09:21:56 2025   01:31:05        316.199\n",
    "143    3       Thu Jul 10 08:32:48 2025 Thu Jul 10 10:20:38 2025   01:47:50        267.063\n",
    "144    1       Thu Jul 10 09:25:40 2025 Thu Jul 10 10:44:49 2025   01:19:09        363.910\n",
    "144    2       Thu Jul 10 10:49:36 2025 Thu Jul 10 12:07:26 2025   01:17:50        370.070\n",
    "144    3       Thu Jul 10 12:12:52 2025 Thu Jul 10 13:33:05 2025   01:20:13        359.040\n",
    "145    1       Thu Jul 10 13:38:12 2025 Thu Jul 10 15:24:55 2025   01:46:43        269.880\n",
    "145    2       Thu Jul 10 15:28:33 2025 Thu Jul 10 17:15:00 2025   01:46:27        270.538\n",
    "145    3       Thu Jul 10 17:18:30 2025 Thu Jul 10 19:06:08 2025   01:47:38        267.579\n",
    "146    1       Thu Jul 10 19:11:29 2025 Thu Jul 10 20:30:57 2025   01:19:28        362.369\n",
    "146    2       Thu Jul 10 20:36:51 2025 Thu Jul 10 22:00:37 2025   01:23:46        343.796\n",
    "146    3       Thu Jul 10 22:07:54 2025 Thu Jul 10 23:28:41 2025   01:20:47        356.507\n",
    "147    1       Thu Jul 10 23:33:19 2025 Fri Jul 11 00:51:16 2025   01:17:57        369.442\n",
    "147    2       Fri Jul 11 00:55:27 2025 Fri Jul 11 02:10:43 2025   01:15:16        382.631\n",
    "147    3       Fri Jul 11 02:15:33 2025 Fri Jul 11 03:27:31 2025   01:11:58        400.185\n",
    "148    1       Fri Jul 11 02:26:13 2025 Fri Jul 11 03:51:39 2025   01:25:26        337.127\n",
    "148    2       Fri Jul 11 03:30:59 2025 Fri Jul 11 04:52:45 2025   01:21:46        352.252\n",
    "148    3       Fri Jul 11 03:58:27 2025 Fri Jul 11 05:23:05 2025   01:24:38        340.253\n",
    "149    1       Fri Jul 11 04:57:15 2025 Fri Jul 11 06:21:53 2025   01:24:38        340.289\n",
    "149    2       Fri Jul 11 05:26:54 2025 Fri Jul 11 07:13:18 2025   01:46:24        270.696\n",
    "149    3       Fri Jul 11 06:28:07 2025 Fri Jul 11 07:52:53 2025   01:24:46        339.761\n",
    "151    1       Fri Jul 11 08:07:22 2025 Fri Jul 11 09:26:34 2025   01:19:12        363.650\n",
    "151    2       Fri Jul 11 08:28:40 2025 Fri Jul 11 09:52:52 2025   01:24:12        342.053\n",
    "151    3       Fri Jul 11 09:57:32 2025 Fri Jul 11 11:44:50 2025   01:47:18        268.422\n",
    "152    1       Fri Jul 11 11:50:09 2025 Fri Jul 11 13:18:23 2025   01:28:14        326.408\n",
    "152    2       Fri Jul 11 13:23:13 2025 Fri Jul 11 14:56:15 2025   01:33:02        309.566\n",
    "152    3       Fri Jul 11 14:56:00 2025 Fri Jul 11 16:47:27 2025   01:51:27        258.423\n",
    "153    1       Fri Jul 11 14:55:58 2025 Fri Jul 11 16:21:40 2025   01:25:42        336.044\n",
    "153    2       Fri Jul 11 15:07:39 2025 Fri Jul 11 16:33:01 2025   01:25:22        337.364\n",
    "153    3       Fri Jul 11 16:37:44 2025 Fri Jul 11 18:04:14 2025   01:26:30        332.898\n",
    "154    1       Fri Jul 11 17:02:19 2025 Fri Jul 11 18:28:56 2025   01:26:37        332.529\n",
    "154    2       Fri Jul 11 18:35:17 2025 Fri Jul 11 20:21:48 2025   01:46:31        270.359\n",
    "154    3       Fri Jul 11 20:25:48 2025 Fri Jul 11 22:11:14 2025   01:45:26        273.170\n",
    "155    1       Fri Jul 11 22:17:31 2025 Fri Jul 11 23:59:01 2025   01:41:30        283.734\n",
    "155    2       Sat Jul 12 00:04:51 2025 Sat Jul 12 01:48:11 2025   01:43:20        278.691\n",
    "155    3       Sat Jul 12 01:53:27 2025 Sat Jul 12 03:38:01 2025   01:44:34        275.404\n",
    "156    1       Sat Jul 12 03:48:19 2025 Sat Jul 12 05:32:23 2025   01:44:04        276.743\n",
    "156    2       Sat Jul 12 05:09:16 2025 Sat Jul 12 06:54:41 2025   01:45:25        273.176\n",
    "156    3       Sat Jul 12 05:39:20 2025 Sat Jul 12 07:20:48 2025   01:41:28        283.847\n",
    "157    1       Sat Jul 12 07:28:18 2025 Sat Jul 12 09:10:56 2025   01:42:38        280.612\n",
    "157    2       Sat Jul 12 07:50:03 2025 Sat Jul 12 09:21:51 2025   01:31:48        313.771\n",
    "157    3       Sat Jul 12 09:18:27 2025 Sat Jul 12 11:03:19 2025   01:44:52        274.658\n",
    "158    1       Sat Jul 12 09:28:11 2025 Sat Jul 12 10:52:45 2025   01:24:34        340.603\n",
    "158    2       Sat Jul 12 11:14:34 2025 Sat Jul 12 12:38:14 2025   01:23:40        344.179\n",
    "158    3       Sat Jul 12 12:48:11 2025 Sat Jul 12 14:12:44 2025   01:24:33        340.592\n",
    "159    1       Sat Jul 12 14:21:53 2025 Sat Jul 12 16:02:47 2025   01:40:54        285.455\n",
    "159    2       Sat Jul 12 16:09:04 2025 Sat Jul 12 17:30:26 2025   01:21:22        353.925\n",
    "159    3       Sat Jul 12 17:40:22 2025 Sat Jul 12 19:20:43 2025   01:40:21        286.982\n",
    "160    1       Sat Jul 12 19:30:22 2025 Sat Jul 12 20:55:52 2025   01:25:30        336.808\n",
    "160    2       Sat Jul 12 21:03:18 2025 Sat Jul 12 22:32:30 2025   01:29:12        322.908\n",
    "160    3       Sat Jul 12 22:38:25 2025 Sun Jul 13 00:05:47 2025   01:27:22        329.662\n",
    "161    1       Sat Jul 12 23:56:41 2025 Sun Jul 13 01:39:03 2025   01:42:22        281.312\n",
    "161    2       Sun Jul 13 00:12:02 2025 Sun Jul 13 01:54:04 2025   01:42:02        282.288\n",
    "161    3       Sun Jul 13 01:46:15 2025 Sun Jul 13 03:29:52 2025   01:43:37        277.957\n",
    "162    1       Sun Jul 13 02:01:01 2025 Sun Jul 13 03:45:56 2025   01:44:55        274.522\n",
    "162    2       Sun Jul 13 03:37:10 2025 Sun Jul 13 05:19:29 2025   01:42:19        281.473\n",
    "162    3       Sun Jul 13 03:51:23 2025 Sun Jul 13 05:35:45 2025   01:44:22        275.949\n",
    "163    1       Sun Jul 13 05:29:22 2025 Sun Jul 13 06:54:26 2025   01:25:04        338.521\n",
    "163    2       Sun Jul 13 05:45:56 2025 Sun Jul 13 07:09:36 2025   01:23:40        344.249\n",
    "163    3       Sun Jul 13 06:32:46 2025 Sun Jul 13 07:55:43 2025   01:22:57        347.161\n",
    "164    1       Sun Jul 13 06:32:46 2025 Sun Jul 13 07:56:06 2025   01:23:20        345.588\n",
    "164    2       Sun Jul 13 07:05:44 2025 Sun Jul 13 08:48:58 2025   01:43:14        278.962\n",
    "164    3       Sun Jul 13 07:18:17 2025 Sun Jul 13 09:02:31 2025   01:44:14        276.332\n",
    "165    1       Sun Jul 13 08:05:50 2025 Sun Jul 13 09:52:50 2025   01:47:00        269.145\n",
    "165    2       Sun Jul 13 08:06:10 2025 Sun Jul 13 09:54:12 2025   01:48:02        266.562\n",
    "165    3       Sun Jul 13 09:17:33 2025 Sun Jul 13 11:03:50 2025   01:46:17        270.971\n",
    "166    1       Sun Jul 13 09:59:49 2025 Sun Jul 13 11:40:43 2025   01:40:54        285.426\n",
    "166    2       Sun Jul 13 09:59:50 2025 Sun Jul 13 11:24:33 2025   01:24:43        339.929\n",
    "166    3       Sun Jul 13 11:36:10 2025 Sun Jul 13 13:00:34 2025   01:24:24        341.219\n",
    "167    1       Sun Jul 13 11:51:43 2025 Sun Jul 13 13:19:15 2025   01:27:32        329.050\n",
    "167    2       Sun Jul 13 13:09:52 2025 Sun Jul 13 14:35:35 2025   01:25:43        336.014\n",
    "167    3       Sun Jul 13 13:30:31 2025 Sun Jul 13 14:57:29 2025   01:26:58        331.177\n",
    "168    1       Sun Jul 13 14:42:06 2025 Sun Jul 13 16:27:25 2025   01:45:19        273.492\n",
    "168    2       Sun Jul 13 15:46:34 2025 Sun Jul 13 17:33:47 2025   01:47:13        268.645\n",
    "168    3       Sun Jul 13 17:40:45 2025 Sun Jul 13 19:26:07 2025   01:45:22        273.293\n",
    "170    1       Sun Jul 13 19:51:00 2025 Sun Jul 13 21:37:15 2025   01:46:15        271.044\n",
    "170    2       Sun Jul 13 21:46:35 2025 Sun Jul 13 23:27:03 2025   01:40:28        286.633\n",
    "170    3       Sun Jul 13 23:36:26 2025 Mon Jul 14 01:19:27 2025   01:43:01        279.567\n",
    "171    1       Mon Jul 14 01:28:42 2025 Mon Jul 14 03:02:23 2025   01:33:41        307.380\n",
    "171    2       Mon Jul 14 02:03:43 2025 Mon Jul 14 03:37:24 2025   01:33:41        307.386\n",
    "171    3       Mon Jul 14 03:14:54 2025 Mon Jul 14 04:50:42 2025   01:35:48        300.634\n",
    "172    1       Mon Jul 14 05:08:08 2025 Mon Jul 14 06:30:29 2025   01:22:21        349.764\n",
    "172    2       Mon Jul 14 06:44:54 2025 Mon Jul 14 08:27:06 2025   01:42:12        281.798\n",
    "172    3       Mon Jul 14 08:31:36 2025 Mon Jul 14 09:54:01 2025   01:22:25        349.390\n",
    "173    1       Mon Jul 14 10:03:22 2025 Mon Jul 14 11:21:52 2025   01:18:30        366.873\n",
    "173    2       Mon Jul 14 11:30:19 2025 Mon Jul 14 12:49:10 2025   01:18:51        365.256\n",
    "173    3       Mon Jul 14 12:58:48 2025 Mon Jul 14 14:34:43 2025   01:35:55        300.292\n",
    "174    1       Tue Jul 15 03:03:47 2025 Tue Jul 15 04:47:13 2025   01:43:26        278.427\n",
    "174    2       Tue Jul 15 04:55:37 2025 Tue Jul 15 06:37:57 2025   01:42:20        281.422\n",
    "174    3       Tue Jul 15 06:45:13 2025 Tue Jul 15 08:26:50 2025   01:41:37        283.429\n",
    "175    1       Tue Jul 15 08:35:03 2025 Tue Jul 15 10:19:48 2025   01:44:45        274.961\n",
    "175    2       Tue Jul 15 10:30:31 2025 Tue Jul 15 11:56:42 2025   01:26:11        334.114\n",
    "175    3       Tue Jul 15 12:04:41 2025 Tue Jul 15 13:52:58 2025   01:48:17        265.947\n",
    "176    1       Tue Jul 15 13:59:11 2025 Tue Jul 15 15:21:06 2025   01:21:55        351.520\n",
    "176    2       Tue Jul 15 15:28:50 2025 Tue Jul 15 17:13:24 2025   01:44:34        275.454\n",
    "176    3       Tue Jul 15 17:23:09 2025 Tue Jul 15 18:50:11 2025   01:27:02        330.937\n",
    "177    1       Tue Jul 15 19:00:55 2025 Tue Jul 15 20:36:01 2025   01:35:06        302.824\n",
    "177    2       Tue Jul 15 20:45:06 2025 Tue Jul 15 22:20:17 2025   01:35:11        302.577\n",
    "177    3       Tue Jul 15 22:30:04 2025 Wed Jul 16 00:05:38 2025   01:35:34        301.389\n",
    "178    1       Wed Jul 16 00:14:45 2025 Wed Jul 16 01:57:47 2025   01:43:02        279.525\n",
    "178    2       Wed Jul 16 02:06:36 2025 Wed Jul 16 03:53:45 2025   01:47:09        268.761\n",
    "178    3       Wed Jul 16 04:05:55 2025 Wed Jul 16 05:30:21 2025   01:24:26        341.151\n",
    "179    1       Wed Jul 16 05:41:47 2025 Wed Jul 16 07:32:45 2025   01:50:58        259.541\n",
    "179    2       Wed Jul 16 07:43:43 2025 Wed Jul 16 09:31:28 2025   01:47:45        267.259\n",
    "179    3       Wed Jul 16 09:45:50 2025 Wed Jul 16 11:37:04 2025   01:51:14        258.899\n",
    "180    1       Wed Jul 16 11:42:28 2025 Wed Jul 16 12:59:59 2025   01:17:31        371.494\n",
    "180    2       Wed Jul 16 13:05:33 2025 Wed Jul 16 14:23:56 2025   01:18:23        367.446\n",
    "180    3       Wed Jul 16 14:27:45 2025 Wed Jul 16 16:06:30 2025   01:38:45        291.633\n",
    "181    1       Wed Jul 16 16:14:50 2025 Wed Jul 16 17:50:35 2025   01:35:45        300.770\n",
    "181    2       Wed Jul 16 18:02:37 2025 Wed Jul 16 19:39:07 2025   01:36:30        298.461\n",
    "181    3       Wed Jul 16 19:46:51 2025 Wed Jul 16 21:23:44 2025   01:36:53        297.283\n",
    "182    1       Wed Jul 16 21:31:38 2025 Wed Jul 16 23:20:56 2025   01:49:18        263.483\n",
    "182    2       Wed Jul 16 23:30:07 2025 Thu Jul 17 01:20:33 2025   01:50:26        260.789\n",
    "182    3       Thu Jul 17 01:29:39 2025 Thu Jul 17 03:03:15 2025   01:33:36        307.721\n",
    "183    1       Thu Jul 17 03:12:28 2025 Thu Jul 17 04:55:29 2025   01:43:01        279.580\n",
    "183    2       Thu Jul 17 05:00:54 2025 Thu Jul 17 06:24:47 2025   01:23:53        343.326\n",
    "183    3       Thu Jul 17 06:29:53 2025 Thu Jul 17 08:18:10 2025   01:48:17        266.002\n",
    "184    1       Thu Jul 17 08:26:38 2025                            --:--:--             NA\n",
    "184    2       Thu Jul 17 08:34:56 2025                            --:--:--             NA\n",
    "184    3       Thu Jul 17 08:45:09 2025                            --:--:--             NA\n",
    "185    1       Thu Jul 17 09:19:35 2025 Thu Jul 17 10:39:11 2025   01:19:36        361.810\n",
    "185    2       Thu Jul 17 10:45:35 2025 Thu Jul 17 12:22:03 2025   01:36:28        298.551\n",
    "185    3       Thu Jul 17 12:27:33 2025 Thu Jul 17 13:46:36 2025   01:19:03        364.313\n",
    "186    1       Thu Jul 17 13:57:42 2025 Thu Jul 17 15:38:15 2025   01:40:33        286.437\n",
    "186    2       Thu Jul 17 15:42:24 2025 Thu Jul 17 17:20:03 2025   01:37:39        294.923\n",
    "186    3       Thu Jul 17 17:25:07 2025 Thu Jul 17 19:04:16 2025   01:39:09        290.500\n",
    "187    1       Thu Jul 17 19:08:02 2025 Thu Jul 17 21:00:05 2025   01:52:03        257.023\n",
    "187    2       Thu Jul 17 21:06:27 2025 Thu Jul 17 22:35:59 2025   01:29:32        321.657\n",
    "187    3       Thu Jul 17 22:40:40 2025 Fri Jul 18 00:32:05 2025   01:51:25        258.502\n",
    "188    1       Fri Jul 18 00:40:09 2025 Fri Jul 18 02:34:13 2025   01:54:04        252.504\n",
    "188    2       Fri Jul 18 02:38:11 2025 Fri Jul 18 04:32:43 2025   01:54:32        251.469\n",
    "188    3       Fri Jul 18 04:38:19 2025 Fri Jul 18 06:31:16 2025   01:52:57        254.984\n",
    "189    1       Fri Jul 18 06:16:48 2025 Fri Jul 18 07:53:02 2025   01:36:14        299.232\n",
    "189    2       Fri Jul 18 06:35:06 2025 Fri Jul 18 07:55:30 2025   01:20:24        358.226\n",
    "189    3       Fri Jul 18 07:59:19 2025 Fri Jul 18 09:34:53 2025   01:35:34        301.367\n",
    "190    1       Fri Jul 18 08:02:14 2025 Fri Jul 18 09:55:08 2025   01:52:54        255.091\n",
    "190    2       Fri Jul 18 09:58:31 2025 Fri Jul 18 11:28:23 2025   01:29:52        320.516\n",
    "190    3       Fri Jul 18 11:34:56 2025 Fri Jul 18 13:05:12 2025   01:30:16        319.032\n",
    "191    1       Fri Jul 18 13:10:20 2025 Fri Jul 18 14:29:29 2025   01:19:09        363.914\n",
    "191    2       Fri Jul 18 14:35:46 2025 Fri Jul 18 15:57:27 2025   01:21:41        352.539\n",
    "191    3       Fri Jul 18 16:04:53 2025 Fri Jul 18 17:26:49 2025   01:21:56        351.438\n",
    "192    1       Fri Jul 18 17:33:08 2025 Fri Jul 18 19:16:49 2025   01:43:41        277.779\n",
    "192    2       Fri Jul 18 19:20:43 2025 Fri Jul 18 21:04:33 2025   01:43:50        277.359\n",
    "192    3       Fri Jul 18 21:13:26 2025 Fri Jul 18 22:59:37 2025   01:46:11        271.209\n",
    "193    1       Fri Jul 18 23:07:40 2025 Sat Jul 19 00:30:39 2025   01:22:59        347.075\n",
    "193    2       Sat Jul 19 00:37:21 2025 Sat Jul 19 02:21:13 2025   01:43:52        277.270\n",
    "193    3       Sat Jul 19 02:25:13 2025 Sat Jul 19 04:07:49 2025   01:42:36        280.733>\"\"\"\n",
    "# Replace the \"...\" with the full middle of your block, or set DATA=None and\n",
    "# use a file path:\n",
    "\n",
    "# Option B: read from a file path (set to a string like \"/path/to/file.txt\")\n",
    "DATA_FILE = None  # e.g., \"/home/you/sim_table.txt\"\n",
    "\n",
    "# Write a CSV too?\n",
    "WRITE_CSV = True\n",
    "CSV_PATH = \"simulation_times.csv\"\n",
    "\n",
    "# === PARSER =================================================================\n",
    "\n",
    "def parse_block(text: str) -> List[Dict[str, Optional[str]]]:\n",
    "    rows: List[Dict[str, Optional[str]]] = []\n",
    "    for raw in text.strip().splitlines():\n",
    "        line = raw.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Strip leading \"<\" and trailing \">\" if present\n",
    "        if line.startswith(\"<\"):\n",
    "            line = line[1:].lstrip()\n",
    "        if line.endswith(\">\"):\n",
    "            line = line[:-1].rstrip()\n",
    "\n",
    "        parts = line.split()\n",
    "        if len(parts) < 8:\n",
    "            # too short to be valid; skip\n",
    "            continue\n",
    "\n",
    "        mol = parts[0]\n",
    "        rep = parts[1]\n",
    "\n",
    "        # start timestamp is 5 tokens after rep\n",
    "        start = \" \".join(parts[2:7])\n",
    "\n",
    "        # duration + performance are always the last two tokens\n",
    "        dur_token = parts[-2] if len(parts) >= 2 else \"\"\n",
    "        perf_token = parts[-1] if len(parts) >= 1 else \"\"\n",
    "\n",
    "        # end timestamp exists when we have ≥14 tokens (2 id tokens + 5 start + 5 end + 2 tail)\n",
    "        end = \" \".join(parts[7:12]) if len(parts) >= 14 else \"\"\n",
    "\n",
    "        # normalize duration/performance\n",
    "        duration = None if dur_token == \"--:--:--\" else dur_token\n",
    "        performance = None if perf_token == \"NA\" else perf_token\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"Molecule\": mol,\n",
    "                \"Replicate\": rep,\n",
    "                \"Start\": start,\n",
    "                \"End\": end,\n",
    "                \"Duration\": duration,        # \"HH:MM:SS\" or None\n",
    "                \"Performance_ns_day\": performance,  # string number or None\n",
    "            }\n",
    "        )\n",
    "    return rows\n",
    "\n",
    "\n",
    "def hhmmss_to_seconds(hhmmss: str) -> int:\n",
    "    h, m, s = hhmmss.split(\":\")\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "\n",
    "def seconds_to_hhmmss(sec: float) -> str:\n",
    "    sec = int(round(sec))\n",
    "    return str(timedelta(seconds=sec))\n",
    "\n",
    "\n",
    "# === MAIN ===================================================================\n",
    "\n",
    "# Load text\n",
    "if DATA is None and DATA_FILE:\n",
    "    with open(DATA_FILE, \"r\") as f:\n",
    "        DATA = f.read()\n",
    "elif DATA is None:\n",
    "    raise SystemExit(\"No input provided. Set DATA (pasted text) or DATA_FILE (path).\")\n",
    "\n",
    "# Parse\n",
    "records = parse_block(DATA)\n",
    "\n",
    "# Compute numeric durations (seconds) for completed rows\n",
    "for r in records:\n",
    "    d = r[\"Duration\"]\n",
    "    r[\"Duration_seconds\"] = hhmmss_to_seconds(d) if d else None\n",
    "\n",
    "# Display table (prefer pandas if available)\n",
    "headers = [\"Molecule\", \"Replicate\", \"Start\", \"End\", \"Duration\", \"Performance_ns_day\"]\n",
    "if HAVE_PANDAS:\n",
    "    df = pd.DataFrame(records, columns=headers + [\"Duration_seconds\"])\n",
    "    # Show a clean view\n",
    "    display_cols = headers  # hide the seconds helper by default\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(df[display_cols])\n",
    "    except Exception:\n",
    "        print(df[display_cols].to_string(index=False))\n",
    "else:\n",
    "    # fallback pretty print\n",
    "    widths = [8, 9, 24, 24, 10, 18]\n",
    "    print(\"\".join(h.ljust(w) for h, w in zip(headers, widths)))\n",
    "    print(\"-\" * sum(widths))\n",
    "    for r in records:\n",
    "        row = [\n",
    "            r[\"Molecule\"] or \"\",\n",
    "            r[\"Replicate\"] or \"\",\n",
    "            r[\"Start\"] or \"\",\n",
    "            r[\"End\"] or \"\",\n",
    "            r[\"Duration\"] or \"\",\n",
    "            r[\"Performance_ns_day\"] or \"\",\n",
    "        ]\n",
    "        print(\"\".join(str(val).ljust(w) for val, w in zip(row, widths)))\n",
    "\n",
    "# Write CSV if requested\n",
    "if WRITE_CSV:\n",
    "    with open(CSV_PATH, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(headers)\n",
    "        for r in records:\n",
    "            writer.writerow([\n",
    "                r[\"Molecule\"],\n",
    "                r[\"Replicate\"],\n",
    "                r[\"Start\"],\n",
    "                r[\"End\"],\n",
    "                r[\"Duration\"] if r[\"Duration\"] else \"\",\n",
    "                r[\"Performance_ns_day\"] if r[\"Performance_ns_day\"] else \"\",\n",
    "            ])\n",
    "    print(f\"\\nSaved CSV → {CSV_PATH}\")\n",
    "\n",
    "# Averages\n",
    "completed_secs = [r[\"Duration_seconds\"] for r in records if r[\"Duration_seconds\"] is not None]\n",
    "overall_avg = seconds_to_hhmmss(sum(completed_secs)/len(completed_secs)) if completed_secs else \"NA\"\n",
    "\n",
    "# per-molecule avg (only completed)\n",
    "per_mol: Dict[str, List[int]] = {}\n",
    "for r in records:\n",
    "    if r[\"Duration_seconds\"] is not None:\n",
    "        per_mol.setdefault(r[\"Molecule\"], []).append(r[\"Duration_seconds\"])\n",
    "\n",
    "per_mol_avg = {mol: seconds_to_hhmmss(sum(v)/len(v)) for mol, v in per_mol.items()}\n",
    "\n",
    "print(\"\\n[AVERAGES]\")\n",
    "print(f\"Overall average duration (completed only): {overall_avg}\")\n",
    "print(f\"Per-molecule average durations (completed only):\")\n",
    "# Pretty print sorted by molecule id (as int if possible)\n",
    "def sort_key(k: str):\n",
    "    try:\n",
    "        return int(k)\n",
    "    except:\n",
    "        return k\n",
    "\n",
    "for mol in sorted(per_mol_avg.keys(), key=sort_key):\n",
    "    print(f\"  {mol}: {per_mol_avg[mol]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
