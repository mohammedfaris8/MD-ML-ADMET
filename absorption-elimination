{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87f1e79-1562-4746-b25e-afcc740881af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/Mohammed/Desktop/SMALLMOL_MD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43154950-c160-4ff6-8f86-ad11efb449f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ lipophilicity_astrazeneca / RDKit only: Train R²=0.30 | RMSE=1.13 || Test R²=-0.10 | RMSE=1.55\n",
      "▶ lipophilicity_astrazeneca / RDKit+MD: Train R²=1.00 | RMSE=0.00 || Test R²=0.14 | RMSE=1.37\n",
      "▶ lipophilicity_astrazeneca / RDKit+MD (SHAP top 20): Train R²=1.00 | RMSE=0.00 || Test R²=0.02 | RMSE=1.47\n",
      "▶ solubility_aqsoldb / RDKit only: Train R²=0.26 | RMSE=1.41 || Test R²=-0.06 | RMSE=1.72\n",
      "▶ solubility_aqsoldb / RDKit+MD: Train R²=0.83 | RMSE=0.67 || Test R²=-0.06 | RMSE=1.73\n",
      "▶ solubility_aqsoldb / RDKit+MD (SHAP top 20): Train R²=0.82 | RMSE=0.69 || Test R²=-0.14 | RMSE=1.79\n",
      "▶ half_life_obach / RDKit only: Train R²=0.29 | RMSE=17.98 || Test R²=-1.17 | RMSE=9.73\n",
      "▶ half_life_obach / RDKit+MD: Train R²=0.29 | RMSE=17.92 || Test R²=-1.10 | RMSE=9.56\n",
      "▶ half_life_obach / RDKit+MD (SHAP top 20): Train R²=0.29 | RMSE=18.03 || Test R²=-1.15 | RMSE=9.66\n",
      "\n",
      "Saved → xgb_regression_RDKit_RDKitMD_SHAP_train_test.csv\n",
      "                  Dataset Feature_Set    Variant  Train_R2  Train_RMSE  Test_R2  Test_RMSE  n_features  N_train  N_test                                                                                              best_params\n",
      "lipophilicity_astrazeneca  RDKit only   Baseline      0.30        1.13    -0.10       1.55         129       84      21 {'subsample': 0.7, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.005, 'colsample_bytree': 0.7}\n",
      "lipophilicity_astrazeneca    RDKit+MD   Baseline      1.00        0.00     0.14       1.37         151       84      21  {'subsample': 0.9, 'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.05, 'colsample_bytree': 0.7}\n",
      "lipophilicity_astrazeneca    RDKit+MD SHAP_top20      1.00        0.00     0.02       1.47          20       84      21  {'subsample': 0.9, 'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.05, 'colsample_bytree': 0.7}\n",
      "       solubility_aqsoldb  RDKit only   Baseline      0.26        1.41    -0.06       1.72         129       77      20 {'subsample': 0.7, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.005, 'colsample_bytree': 0.7}\n",
      "       solubility_aqsoldb    RDKit+MD   Baseline      0.83        0.67    -0.06       1.73         151       77      20  {'subsample': 0.9, 'n_estimators': 200, 'max_depth': 2, 'learning_rate': 0.02, 'colsample_bytree': 0.9}\n",
      "       solubility_aqsoldb    RDKit+MD SHAP_top20      0.82        0.69    -0.14       1.79          20       77      20  {'subsample': 0.9, 'n_estimators': 200, 'max_depth': 2, 'learning_rate': 0.02, 'colsample_bytree': 0.9}\n",
      "          half_life_obach  RDKit only   Baseline      0.29       17.98    -1.17       9.73         129      102      26 {'subsample': 0.7, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.005, 'colsample_bytree': 0.7}\n",
      "          half_life_obach    RDKit+MD   Baseline      0.29       17.92    -1.10       9.56         151      102      26 {'subsample': 0.7, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.005, 'colsample_bytree': 0.7}\n",
      "          half_life_obach    RDKit+MD SHAP_top20      0.29       18.03    -1.15       9.66          20      102      26 {'subsample': 0.7, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.005, 'colsample_bytree': 0.7}\n",
      "Saved → xgb_shap_rankings_alldatasets.csv\n"
     ]
    }
   ],
   "source": [
    "# === XGB regression on 3 datasets (RDKit | RDKit+MD | RDKit+MD SHAP) ===\n",
    "# Metrics: Train/Test R2, RMSE. Saves SHAP plots per dataset.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "DATA_FILE    = \"MD_ADMET_RDKIT_FS.csv\"\n",
    "DATASETS     = [\"lipophilicity_astrazeneca\", \"solubility_aqsoldb\", \"half_life_obach\"]\n",
    "TEST_SIZE    = 0.20\n",
    "RANDOM_STATE = 42\n",
    "N_JOBS       = -1\n",
    "\n",
    "# SHAP settings (RDKit+MD only)\n",
    "TOP_K               = 20\n",
    "MAKE_SHAP_PLOTS     = True\n",
    "PLOT_MAX_FEATURES   = 20\n",
    "SHAP_BG_MAX_SAMPLES = 1000  # background cap for speed/memory\n",
    "\n",
    "# XGB grid\n",
    "param_grid = {\n",
    "    \"n_estimators\":     [100, 200, 300, 400, 500, 600, 800],\n",
    "    \"max_depth\":        [2, 3, 4, 5, 6],\n",
    "    \"learning_rate\":    [0.005, 0.01, 0.02, 0.05, 0.1],\n",
    "    \"subsample\":        [0.6, 0.7, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "meta_cols = [\"ID\", \"smiles\", \"dataset\", \"Y\"]\n",
    "md_cols = [\n",
    "    \"mean_length\",\"std_length\",\"min_length\",\"max_length\",\n",
    "    \"mean_rg\",\"std_rg\",\n",
    "    \"mean_area\",\"std_area\",\n",
    "    \"mean_tpsa\",\"std_tpsa\",\n",
    "    \"convergence_score\",\n",
    "    \"folding_index_rg\",\"folding_index_l\",\n",
    "    \"flexibility_index\",\n",
    "    \"mean_com_disp\",\"max_com_disp\",\"p95_com_disp\",\n",
    "    \"mean_rmsd\",\"max_rmsd\",\n",
    "    \"diff_coeff\",\"hbonds_mean\",\"hbonds_std\"\n",
    "]\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def build_feature_blocks(df_d):\n",
    "    y = df_d[\"Y\"].astype(float).reset_index(drop=True)\n",
    "    for c in md_cols:\n",
    "        if c not in df_d.columns:\n",
    "            df_d[c] = np.nan\n",
    "    X_rdkit = (df_d.drop(columns=meta_cols + md_cols, errors=\"ignore\")\n",
    "                  .select_dtypes(include=[np.number]).reset_index(drop=True))\n",
    "    X_all   = (df_d.drop(columns=meta_cols, errors=\"ignore\")\n",
    "                  .select_dtypes(include=[np.number]).reset_index(drop=True))\n",
    "    return X_rdkit, X_all, y\n",
    "\n",
    "def holdout_indices(n, test_size=0.2, rs=42):\n",
    "    ss = ShuffleSplit(n_splits=1, test_size=test_size, random_state=rs)\n",
    "    (tr, te), = ss.split(np.arange(n))\n",
    "    return tr, te\n",
    "\n",
    "def tune_and_fit_xgb(X_tr_imp, y_tr, rs=42):\n",
    "    base = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=rs,\n",
    "        n_jobs=N_JOBS,\n",
    "        tree_method=\"hist\",\n",
    "    )\n",
    "    inner = KFold(n_splits=5, shuffle=True, random_state=rs)\n",
    "    search = RandomizedSearchCV(\n",
    "        base,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=40,\n",
    "        scoring=\"r2\",\n",
    "        cv=inner,\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=rs,\n",
    "        refit=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    search.fit(X_tr_imp, y_tr)\n",
    "    return search.best_estimator_, search.best_params_\n",
    "\n",
    "def evaluate(model, X_tr_imp, y_tr, X_te_imp, y_te, label):\n",
    "    # train\n",
    "    yhat_tr = model.predict(X_tr_imp)\n",
    "    r2_tr   = r2_score(y_tr, yhat_tr)\n",
    "    rmse_tr = mean_squared_error(y_tr, yhat_tr, squared=False)\n",
    "    # test\n",
    "    yhat_te = model.predict(X_te_imp)\n",
    "    r2_te   = r2_score(y_te, yhat_te)\n",
    "    rmse_te = mean_squared_error(y_te, yhat_te, squared=False)\n",
    "    print(f\"▶ {label}: Train R²={r2_tr:.2f} | RMSE={rmse_tr:.2f} || Test R²={r2_te:.2f} | RMSE={rmse_te:.2f}\")\n",
    "    return r2_tr, rmse_tr, r2_te, rmse_te\n",
    "\n",
    "def shap_rank(model, X_tr_imp, feature_names, top_k=20):\n",
    "    # Use TreeExplainer when possible\n",
    "    try:\n",
    "        expl = shap.TreeExplainer(model)\n",
    "        sv   = expl.shap_values(X_tr_imp)\n",
    "    except Exception:\n",
    "        expl = shap.Explainer(model, X_tr_imp)\n",
    "        sv   = expl(X_tr_imp).values\n",
    "    mean_abs = np.abs(sv).mean(axis=0)\n",
    "    order    = np.argsort(-mean_abs)\n",
    "    feats    = feature_names[order]\n",
    "    imps     = mean_abs[order]\n",
    "    return feats[:top_k], imps[:top_k], feats, imps, sv\n",
    "\n",
    "def save_shap_plots(values, X_imp, feature_names, title_prefix, max_display=20):\n",
    "    if not MAKE_SHAP_PLOTS:\n",
    "        return\n",
    "    # Beeswarm\n",
    "    shap.summary_plot(values, X_imp, feature_names=list(feature_names),\n",
    "                      show=False, max_display=max_display)\n",
    "    plt.title(f\"{title_prefix} — SHAP (beeswarm)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{title_prefix.replace('/','_').replace(' ','_')}_SHAP_beeswarm.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Bar (mean |SHAP|)\n",
    "    shap.summary_plot(values, X_imp, feature_names=list(feature_names),\n",
    "                      plot_type=\"bar\", show=False, max_display=max_display)\n",
    "    plt.title(f\"{title_prefix} — SHAP (bar)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{title_prefix.replace('/','_').replace(' ','_')}_SHAP_bar.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# Run\n",
    "# ---------------------------\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "results = []\n",
    "shap_logs = []\n",
    "\n",
    "for ds in DATASETS:\n",
    "    df_d = df[df[\"dataset\"] == ds].dropna(subset=[\"Y\"]).copy()\n",
    "    if df_d.empty:\n",
    "        print(f\"⚠️ {ds}: no labeled rows, skipping\")\n",
    "        continue\n",
    "\n",
    "    X_rdk, X_all, y = build_feature_blocks(df_d)\n",
    "    tr, te = holdout_indices(len(y), TEST_SIZE, RANDOM_STATE)\n",
    "    def sp(X): return X.iloc[tr].reset_index(drop=True), X.iloc[te].reset_index(drop=True)\n",
    "    Xr_tr, Xr_te = sp(X_rdk)\n",
    "    Xa_tr, Xa_te = sp(X_all)\n",
    "    y_tr, y_te = y.iloc[tr].reset_index(drop=True), y.iloc[te].reset_index(drop=True)\n",
    "\n",
    "    imp_med = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    # --- RDKit only\n",
    "    Xr_tr_imp = imp_med.fit_transform(Xr_tr)\n",
    "    Xr_te_imp = imp_med.transform(Xr_te)\n",
    "    best_rdk, params_rdk = tune_and_fit_xgb(Xr_tr_imp, y_tr, RANDOM_STATE)\n",
    "    r2tr, rmsetr, r2te, rmsete = evaluate(best_rdk, Xr_tr_imp, y_tr, Xr_te_imp, y_te, f\"{ds} / RDKit only\")\n",
    "    results.append({\n",
    "        \"Dataset\": ds, \"Feature_Set\": \"RDKit only\", \"Variant\": \"Baseline\",\n",
    "        \"Train_R2\": round(r2tr,2), \"Train_RMSE\": round(rmsetr,2),\n",
    "        \"Test_R2\": round(r2te,2), \"Test_RMSE\": round(rmsete,2),\n",
    "        \"n_features\": Xr_tr.shape[1], \"N_train\": len(y_tr), \"N_test\": len(y_te),\n",
    "        \"best_params\": params_rdk\n",
    "    })\n",
    "\n",
    "    # --- RDKit + MD (baseline)\n",
    "    Xa_tr_imp = imp_med.fit_transform(Xa_tr)\n",
    "    Xa_te_imp = imp_med.transform(Xa_te)\n",
    "    best_all, params_all = tune_and_fit_xgb(Xa_tr_imp, y_tr, RANDOM_STATE)\n",
    "    r2tr, rmsetr, r2te, rmsete = evaluate(best_all, Xa_tr_imp, y_tr, Xa_te_imp, y_te, f\"{ds} / RDKit+MD\")\n",
    "    results.append({\n",
    "        \"Dataset\": ds, \"Feature_Set\": \"RDKit+MD\", \"Variant\": \"Baseline\",\n",
    "        \"Train_R2\": round(r2tr,2), \"Train_RMSE\": round(rmsetr,2),\n",
    "        \"Test_R2\": round(r2te,2), \"Test_RMSE\": round(rmsete,2),\n",
    "        \"n_features\": Xa_tr.shape[1], \"N_train\": len(y_tr), \"N_test\": len(y_te),\n",
    "        \"best_params\": params_all\n",
    "    })\n",
    "\n",
    "    # SHAP on tuned RDKit+MD model (plots + ranking)\n",
    "    # Optionally thin background for speed\n",
    "    bg_idx = np.random.RandomState(RANDOM_STATE).choice(\n",
    "        Xa_tr_imp.shape[0], size=min(SHAP_BG_MAX_SAMPLES, Xa_tr_imp.shape[0]), replace=False\n",
    "    )\n",
    "    Xa_tr_imp_bg = Xa_tr_imp[bg_idx]\n",
    "\n",
    "    try:\n",
    "        expl_base = shap.TreeExplainer(best_all)\n",
    "        sv_base   = expl_base.shap_values(Xa_tr_imp_bg)\n",
    "    except Exception:\n",
    "        expl_base = shap.Explainer(best_all, Xa_tr_imp_bg)\n",
    "        sv_base   = expl_base(Xa_tr_imp_bg).values\n",
    "\n",
    "    # Save beeswarm + bar plots for the baseline RDKit+MD model\n",
    "    save_shap_plots(sv_base, Xa_tr_imp_bg, Xa_tr.columns.values,\n",
    "                    title_prefix=f\"{ds} / RDKit+MD\", max_display=PLOT_MAX_FEATURES)\n",
    "\n",
    "    # Rank all features (using full training for stability)\n",
    "    top_feats, top_imps, all_feats, all_imps, sv_full = shap_rank(best_all, Xa_tr_imp, Xa_tr.columns.values, TOP_K)\n",
    "    shap_logs.append(pd.DataFrame({\"Dataset\": ds, \"feature\": all_feats, \"mean_abs_shap\": all_imps}))\n",
    "\n",
    "    # --- RDKit + MD (SHAP-selected top-K)\n",
    "    xgb_sel = XGBRegressor(objective=\"reg:squarederror\", random_state=RANDOM_STATE,\n",
    "                           n_jobs=N_JOBS, tree_method=\"hist\", **params_all)\n",
    "    Xa_tr_sel = Xa_tr[top_feats]\n",
    "    Xa_te_sel = Xa_te[top_feats]\n",
    "    Xa_tr_sel_imp = SimpleImputer(strategy=\"median\").fit_transform(Xa_tr_sel)\n",
    "    Xa_te_sel_imp = SimpleImputer(strategy=\"median\").fit_transform(Xa_te_sel)\n",
    "    xgb_sel.fit(Xa_tr_sel_imp, y_tr)\n",
    "    r2tr, rmsetr, r2te, rmsete = evaluate(\n",
    "        xgb_sel, Xa_tr_sel_imp, y_tr, Xa_te_sel_imp, y_te, f\"{ds} / RDKit+MD (SHAP top {TOP_K})\"\n",
    "    )\n",
    "    results.append({\n",
    "        \"Dataset\": ds, \"Feature_Set\": \"RDKit+MD\", \"Variant\": f\"SHAP_top{TOP_K}\",\n",
    "        \"Train_R2\": round(r2tr,2), \"Train_RMSE\": round(rmsetr,2),\n",
    "        \"Test_R2\": round(r2te,2), \"Test_RMSE\": round(rmsete,2),\n",
    "        \"n_features\": len(top_feats), \"N_train\": len(y_tr), \"N_test\": len(y_te),\n",
    "        \"best_params\": params_all\n",
    "    })\n",
    "\n",
    "  # SHAP beeswarm (top 10) for the SHAP-selected model\n",
    "bg_idx_sel = np.random.RandomState(RANDOM_STATE).choice(\n",
    "    Xa_tr_sel_imp.shape[0],\n",
    "    size=min(SHAP_BG_MAX_SAMPLES, Xa_tr_sel_imp.shape[0]),\n",
    "    replace=False\n",
    ")\n",
    "Xa_tr_sel_imp_bg = Xa_tr_sel_imp[bg_idx_sel]\n",
    "\n",
    "try:\n",
    "    expl_sel = shap.TreeExplainer(xgb_sel)\n",
    "    sv_sel   = expl_sel.shap_values(Xa_tr_sel_imp_bg)\n",
    "except Exception:\n",
    "    expl_sel = shap.Explainer(xgb_sel, Xa_tr_sel_imp_bg)\n",
    "    sv_obj   = expl_sel(Xa_tr_sel_imp_bg)\n",
    "    sv_sel   = sv_obj.values\n",
    "\n",
    "# rank by mean |SHAP| using the background set\n",
    "mean_abs_sel = np.abs(sv_sel).mean(axis=0)\n",
    "top10_idx    = np.argsort(-mean_abs_sel)[:10]\n",
    "feat_top10   = np.array(top_feats)[top10_idx]  # top_feats are the columns used in the SHAP-selected model\n",
    "sv_top10     = sv_sel[:, top10_idx]\n",
    "X_bg_top10   = Xa_tr_sel_imp_bg[:, top10_idx]\n",
    "\n",
    "# Beeswarm plot (Top 10 SHAP features only)\n",
    "top10_idx = np.argsort(-np.abs(sv_sel).mean(axis=0))[:10]\n",
    "sv_top10  = sv_sel[:, top10_idx]\n",
    "feat_top10 = np.array(top_feats)[top10_idx]\n",
    "X_bg_top10 = Xa_tr_sel_imp_bg[:, top10_idx]\n",
    "\n",
    "shap.summary_plot(\n",
    "    sv_top10, X_bg_top10,\n",
    "    feature_names=list(feat_top10),\n",
    "    show=False, max_display=10, plot_type=\"dot\"\n",
    ")\n",
    "\n",
    "# Map dataset codes to clean property names\n",
    "name_map = {\n",
    "    \"lipophilicity_astrazeneca\": \"Lipophilicity\",\n",
    "    \"solubility_aqsoldb\": \"Solubility\",\n",
    "    \"half_life_obach\": \"Half-life\"\n",
    "}\n",
    "\n",
    "# Beeswarm plot (Top 10 SHAP features only)\n",
    "top10_idx = np.argsort(-np.abs(sv_sel).mean(axis=0))[:10]\n",
    "sv_top10  = sv_sel[:, top10_idx]\n",
    "feat_top10 = np.array(top_feats)[top10_idx]\n",
    "X_bg_top10 = Xa_tr_sel_imp_bg[:, top10_idx]\n",
    "\n",
    "shap.summary_plot(\n",
    "    sv_top10, X_bg_top10,\n",
    "    feature_names=list(feat_top10),\n",
    "    show=False, max_display=10, plot_type=\"dot\"\n",
    ")\n",
    "\n",
    "# ✅ Use clean property name instead of dataset code\n",
    "property_name = name_map.get(ds, ds)  \n",
    "plt.title(f\"{property_name} — SHAP (Top 10)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{property_name.replace(' ', '_')}_SHAPtop10.png\", dpi=300)\n",
    "plt.close()\n",
    "# ---------------------------\n",
    "# Save\n",
    "# ---------------------------\n",
    "summary = pd.DataFrame(results)\n",
    "summary = summary[[\"Dataset\",\"Feature_Set\",\"Variant\",\n",
    "                   \"Train_R2\",\"Train_RMSE\",\"Test_R2\",\"Test_RMSE\",\n",
    "                   \"n_features\",\"N_train\",\"N_test\",\"best_params\"]]\n",
    "summary.to_csv(\"xgb_regression_RDKit_RDKitMD_SHAP_train_test.csv\", index=False)\n",
    "print(\"\\nSaved → xgb_regression_RDKit_RDKitMD_SHAP_train_test.csv\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "if shap_logs:\n",
    "    pd.concat(shap_logs, ignore_index=True).to_csv(\"xgb_shap_rankings_alldatasets.csv\", index=False)\n",
    "    print(\"Saved → xgb_shap_rankings_alldatasets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735fb059-c314-4254-a88f-df2eaba65142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ lipophilicity_astrazeneca / RDKit only: Train R²=0.54 | RMSE=0.92 || Test R²=-0.30 | RMSE=1.69\n",
      "▶ lipophilicity_astrazeneca / RDKit+MD: Train R²=0.90 | RMSE=0.43 || Test R²=0.05 | RMSE=1.44\n",
      "▶ solubility_aqsoldb / RDKit only: Train R²=0.40 | RMSE=1.27 || Test R²=0.03 | RMSE=1.66\n",
      "▶ solubility_aqsoldb / RDKit+MD: Train R²=0.75 | RMSE=0.82 || Test R²=-0.04 | RMSE=1.71\n",
      "▶ half_life_obach / RDKit only: Train R²=0.37 | RMSE=16.88 || Test R²=-1.43 | RMSE=10.29\n",
      "▶ half_life_obach / RDKit+MD: Train R²=0.36 | RMSE=17.06 || Test R²=-1.45 | RMSE=10.32\n",
      "\n",
      "Saved → rf_regression_RDKit_RDKitMD_train_test.csv\n",
      "                  Dataset Feature_Set Model  Train_R2  Test_R2  Test_RMSE  n_features  N_train  N_test                                                                                                                          best_params\n",
      "lipophilicity_astrazeneca  RDKit only    RF      0.54    -0.30       1.69         129       84      21      {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 4, 'bootstrap': True}\n",
      "lipophilicity_astrazeneca    RDKit+MD    RF      0.90     0.05       1.44         151       84      21 {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
      "       solubility_aqsoldb  RDKit only    RF      0.40     0.03       1.66         129       77      20     {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 6, 'bootstrap': True}\n",
      "       solubility_aqsoldb    RDKit+MD    RF      0.75    -0.04       1.71         151       77      20        {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 4, 'bootstrap': True}\n",
      "          half_life_obach  RDKit only    RF      0.37    -1.43      10.29         129      102      26     {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 12, 'bootstrap': True}\n",
      "          half_life_obach    RDKit+MD    RF      0.36    -1.45      10.32         151      102      26     {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 6, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "# === RF regression on 3 datasets (RDKit | RDKit+MD) ===\n",
    "# Metrics: Train & Test R2, RMSE. No SHAP / no FI selection.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "DATA_FILE    = \"MD_ADMET_RDKIT_FS.csv\"\n",
    "DATASETS     = [\"lipophilicity_astrazeneca\", \"solubility_aqsoldb\", \"half_life_obach\"]\n",
    "TEST_SIZE    = 0.20\n",
    "RANDOM_STATE = 42\n",
    "N_JOBS       = -1\n",
    "\n",
    "# RF grid (plain keys)\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\":       [100, 200, 300, 400, 500, 600],\n",
    "    \"max_depth\":          [None, 4, 6, 8, 12],\n",
    "    \"min_samples_split\":  [2, 5, 10],\n",
    "    \"min_samples_leaf\":   [1, 2, 4],\n",
    "    \"max_features\":       [\"sqrt\", \"log2\", None],\n",
    "    \"bootstrap\":          [True, False],\n",
    "}\n",
    "\n",
    "meta_cols = [\"ID\", \"smiles\", \"dataset\", \"Y\"]\n",
    "md_cols = [\n",
    "    \"mean_length\",\"std_length\",\"min_length\",\"max_length\",\n",
    "    \"mean_rg\",\"std_rg\",\n",
    "    \"mean_area\",\"std_area\",\n",
    "    \"mean_tpsa\",\"std_tpsa\",\n",
    "    \"convergence_score\",\n",
    "    \"folding_index_rg\",\"folding_index_l\",\n",
    "    \"flexibility_index\",\n",
    "    \"mean_com_disp\",\"max_com_disp\",\"p95_com_disp\",\n",
    "    \"mean_rmsd\",\"max_rmsd\",\n",
    "    \"diff_coeff\",\"hbonds_mean\",\"hbonds_std\"\n",
    "]\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def build_feature_blocks(df_d):\n",
    "    \"\"\"Returns numeric X_rdkit, X_all (RDKit+MD), y as float.\"\"\"\n",
    "    y = df_d[\"Y\"].astype(float).reset_index(drop=True)\n",
    "    for c in md_cols:\n",
    "        if c not in df_d.columns:\n",
    "            df_d[c] = np.nan\n",
    "    X_rdkit = (df_d.drop(columns=meta_cols + md_cols, errors=\"ignore\")\n",
    "                  .select_dtypes(include=[np.number]).reset_index(drop=True))\n",
    "    X_all   = (df_d.drop(columns=meta_cols, errors=\"ignore\")\n",
    "                  .select_dtypes(include=[np.number]).reset_index(drop=True))\n",
    "    return X_rdkit, X_all, y\n",
    "\n",
    "def holdout_indices(n, test_size=0.2, rs=42):\n",
    "    ss = ShuffleSplit(n_splits=1, test_size=test_size, random_state=rs)\n",
    "    (tr, te), = ss.split(np.arange(n))\n",
    "    return tr, te\n",
    "\n",
    "def tune_and_fit_rf(X_tr_imp, y_tr, rs=42):\n",
    "    base = RandomForestRegressor(random_state=rs, n_jobs=N_JOBS)\n",
    "    inner = KFold(n_splits=5, shuffle=True, random_state=rs)\n",
    "    search = RandomizedSearchCV(\n",
    "        base,\n",
    "        param_distributions=rf_param_grid,\n",
    "        n_iter=40,\n",
    "        scoring=\"r2\",\n",
    "        cv=inner,\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=rs,\n",
    "        refit=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    search.fit(X_tr_imp, y_tr)\n",
    "    return search.best_estimator_, search.best_params_\n",
    "\n",
    "def eval_train_test(model, X_tr_imp, y_tr, X_te_imp, y_te, label):\n",
    "    # Train\n",
    "    yhat_tr = model.predict(X_tr_imp)\n",
    "    r2_tr   = r2_score(y_tr, yhat_tr)\n",
    "    rmse_tr = mean_squared_error(y_tr, yhat_tr, squared=False)\n",
    "    # Test\n",
    "    yhat_te = model.predict(X_te_imp)\n",
    "    r2_te   = r2_score(y_te, yhat_te)\n",
    "    rmse_te = mean_squared_error(y_te, yhat_te, squared=False)\n",
    "    print(f\"▶ {label}: Train R²={r2_tr:.2f} | RMSE={rmse_tr:.2f} || Test R²={r2_te:.2f} | RMSE={rmse_te:.2f}\")\n",
    "    return r2_tr, rmse_tr, r2_te, rmse_te\n",
    "\n",
    "# ---------------------------\n",
    "# Run\n",
    "# ---------------------------\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "results = []\n",
    "\n",
    "for ds in DATASETS:\n",
    "    df_d = df[df[\"dataset\"] == ds].dropna(subset=[\"Y\"]).copy()\n",
    "    if df_d.empty:\n",
    "        print(f\"⚠️ {ds}: no labeled rows, skipping\")\n",
    "        continue\n",
    "\n",
    "    X_rdk, X_all, y = build_feature_blocks(df_d)\n",
    "    tr, te = holdout_indices(len(y), TEST_SIZE, RANDOM_STATE)\n",
    "    def sp(X): return X.iloc[tr].reset_index(drop=True), X.iloc[te].reset_index(drop=True)\n",
    "    Xr_tr, Xr_te = sp(X_rdk)   # RDKit only\n",
    "    Xa_tr, Xa_te = sp(X_all)   # RDKit+MD\n",
    "    y_tr, y_te   = y.iloc[tr].reset_index(drop=True), y.iloc[te].reset_index(drop=True)\n",
    "\n",
    "    imp_med = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    # --- RDKit only\n",
    "    Xr_tr_imp = imp_med.fit_transform(Xr_tr)\n",
    "    Xr_te_imp = imp_med.transform(Xr_te)\n",
    "    best_rdk, params_rdk = tune_and_fit_rf(Xr_tr_imp, y_tr, RANDOM_STATE)\n",
    "    r2tr, rmsetr, r2te, rmsete = eval_train_test(best_rdk, Xr_tr_imp, y_tr, Xr_te_imp, y_te, f\"{ds} / RDKit only\")\n",
    "    results.append({\n",
    "        \"Dataset\": ds, \"Feature_Set\": \"RDKit only\", \"Model\": \"RF\",\n",
    "        \"Train_R2\": round(r2tr,2), \"Test_R2\": round(r2te,2), \"Test_RMSE\": round(rmsete,2),\n",
    "        \"n_features\": Xr_tr.shape[1], \"N_train\": len(y_tr), \"N_test\": len(y_te),\n",
    "        \"best_params\": params_rdk\n",
    "    })\n",
    "\n",
    "    # --- RDKit + MD\n",
    "    Xa_tr_imp = imp_med.fit_transform(Xa_tr)\n",
    "    Xa_te_imp = imp_med.transform(Xa_te)\n",
    "    best_all, params_all = tune_and_fit_rf(Xa_tr_imp, y_tr, RANDOM_STATE)\n",
    "    r2tr, rmsetr, r2te, rmsete = eval_train_test(best_all, Xa_tr_imp, y_tr, Xa_te_imp, y_te, f\"{ds} / RDKit+MD\")\n",
    "    results.append({\n",
    "        \"Dataset\": ds, \"Feature_Set\": \"RDKit+MD\", \"Model\": \"RF\",\n",
    "        \"Train_R2\": round(r2tr,2), \"Test_R2\": round(r2te,2), \"Test_RMSE\": round(rmsete,2),\n",
    "        \"n_features\": Xa_tr.shape[1], \"N_train\": len(y_tr), \"N_test\": len(y_te),\n",
    "        \"best_params\": params_all\n",
    "    })\n",
    "\n",
    "# ---------------------------\n",
    "# Save (format to match your example)\n",
    "# ---------------------------\n",
    "summary = pd.DataFrame(results)\n",
    "summary = summary[[\n",
    "    \"Dataset\",\"Feature_Set\",\"Model\",\n",
    "    \"Train_R2\",\"Test_R2\",\"Test_RMSE\",\n",
    "    \"n_features\",\"N_train\",\"N_test\",\"best_params\"\n",
    "]]\n",
    "summary.to_csv(\"rf_regression_RDKit_RDKitMD_train_test.csv\", index=False)\n",
    "print(\"\\nSaved → rf_regression_RDKit_RDKitMD_train_test.csv\")\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1572d724-35c8-4e3e-b509-7d4531ca1126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → rf_xgb_regression_merged.csv\n",
      "                  Dataset Feature_Set Model  Train_R2  Test_R2  Test_RMSE  n_features  N_train  N_test                                                                                                                          best_params\n",
      "lipophilicity_astrazeneca  RDKit only    RF      0.54    -0.30       1.69         129       84      21      {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 4, 'bootstrap': True}\n",
      "lipophilicity_astrazeneca    RDKit+MD    RF      0.90     0.05       1.44         151       84      21 {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
      "       solubility_aqsoldb  RDKit only    RF      0.40     0.03       1.66         129       77      20     {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 6, 'bootstrap': True}\n",
      "       solubility_aqsoldb    RDKit+MD    RF      0.75    -0.04       1.71         151       77      20        {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 4, 'bootstrap': True}\n",
      "          half_life_obach  RDKit only    RF      0.37    -1.43      10.29         129      102      26     {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 12, 'bootstrap': True}\n",
      "          half_life_obach    RDKit+MD    RF      0.36    -1.45      10.32         151      102      26     {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 6, 'bootstrap': True}\n",
      "lipophilicity_astrazeneca  RDKit only   XGB      0.46    -0.16       1.60         129       84      21                             {'subsample': 0.9, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.005, 'colsample_bytree': 1.0}\n",
      "lipophilicity_astrazeneca    RDKit+MD   XGB      1.00     0.17       1.35         151       84      21                              {'subsample': 0.9, 'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.02, 'colsample_bytree': 0.7}\n",
      "lipophilicity_astrazeneca    RDKit+MD   XGB      1.00     0.20       1.32          20       84      21                              {'subsample': 0.9, 'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.02, 'colsample_bytree': 0.7}\n",
      "       solubility_aqsoldb  RDKit only   XGB      0.29    -0.09       1.75         129       77      20                             {'subsample': 0.9, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.005, 'colsample_bytree': 1.0}\n",
      "       solubility_aqsoldb    RDKit+MD   XGB      0.52    -0.12       1.78         151       77      20                             {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.005, 'colsample_bytree': 1.0}\n",
      "       solubility_aqsoldb    RDKit+MD   XGB      0.52    -0.08       1.74          20       77      20                             {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.005, 'colsample_bytree': 1.0}\n",
      "          half_life_obach  RDKit only   XGB      0.34    -1.05       9.44         129      102      26                             {'subsample': 0.9, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.005, 'colsample_bytree': 1.0}\n",
      "          half_life_obach    RDKit+MD   XGB      0.39    -0.92       9.13         151      102      26                             {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.005, 'colsample_bytree': 0.9}\n",
      "          half_life_obach    RDKit+MD   XGB      0.39    -0.89       9.07          20      102      26                             {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.005, 'colsample_bytree': 0.9}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both summaries\n",
    "rf  = pd.read_csv(\"rf_regression_RDKit_RDKitMD_train_test.csv\")\n",
    "xgb = pd.read_csv(\"xgb_regression_RDKit_RDKitMD_SHAP_train_test.csv\")\n",
    "\n",
    "# Add a \"Model\" column if not already there\n",
    "if \"Model\" not in rf.columns:\n",
    "    rf[\"Model\"] = \"RF\"\n",
    "if \"Model\" not in xgb.columns:\n",
    "    xgb[\"Model\"] = \"XGB\"\n",
    "\n",
    "# Make sure the column order matches\n",
    "common_cols = [\"Dataset\",\"Feature_Set\",\"Model\",\"Train_R2\", \"Test_R2\", \"Test_RMSE\",\n",
    "               \"n_features\",\"N_train\",\"N_test\",\"best_params\"]\n",
    "\n",
    "rf  = rf[common_cols]\n",
    "xgb = xgb[common_cols]\n",
    "\n",
    "# Merge into one table\n",
    "merged = pd.concat([rf, xgb], ignore_index=True)\n",
    "\n",
    "# Save\n",
    "merged.to_csv(\"rf_xgb_regression_merged.csv\", index=False)\n",
    "\n",
    "print(\"Saved → rf_xgb_regression_merged.csv\")\n",
    "print(merged.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379ff31-97f3-4a13-b6b2-e5bdf44b46d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a6f939-7542-4e4a-866c-4913f475c45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
